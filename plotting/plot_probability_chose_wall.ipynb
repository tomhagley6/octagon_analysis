{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import parse_data.prepare_data as prepare_data\n",
    "import analysis.wall_visibility_and_choice as wall_visibility_and_choice\n",
    "import globals\n",
    "import data_extraction.get_indices as get_indices\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paired boxplots of probability of choosing a wall across any number of conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot_probability_choose_wall(wall_choice_probabilities, wall_choice_labels, ylabel, ylim=(0.0,1), set_aspect=3):\n",
    "    ''' Plotting function to plot wall choice probability paired data across any number\n",
    "        of conditions.\n",
    "        Assumes each datapoint in the pair is from a single subject's session data.\n",
    "        Takes a list of probabilities arrays (for wall choice) and a list of labels for plotting.\n",
    "        List arrays must be of shape num_sessions*num_players. '''\n",
    "\n",
    "\n",
    "    # LVs\n",
    "    num_datasets = len(wall_choice_probabilities)\n",
    "    dataset_size = wall_choice_probabilities[0].size\n",
    "\n",
    "    # Ensure input consistency\n",
    "    assert len(wall_choice_probabilities) == len(wall_choice_labels), \\\n",
    "        \"Number of probabilities and labels must match.\"\n",
    "\n",
    "    # Reshape data and create labels\n",
    "    data = np.concatenate([arr.ravel() for arr in wall_choice_probabilities])\n",
    "    labels = [np.full(arr.size, label) for arr, label in zip(wall_choice_probabilities, wall_choice_labels)]\n",
    "    labels = np.concatenate(labels)\n",
    "\n",
    "    # Create DataFrame for Seaborn\n",
    "    df = pd.DataFrame({\n",
    "        \"Probability\": data,\n",
    "        \"Condition\": labels\n",
    "    })\n",
    "\n",
    "    # # Generate distinct colors for each individual\n",
    "    # colors = plt.cm.viridis(np.linspace(0, 1, (first_wall_seen).size))\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(4*num_datasets, 5))\n",
    "    sns.boxplot(x=\"Condition\", y=\"Probability\", data=df, palette=\"Paired\", width=.8)\n",
    "    \n",
    "    # Draw lines connecting paired data points\n",
    "    for i in range(dataset_size):\n",
    "        # print(f\"{len(wall_choice_labels)}, {len([dataset.ravel()[i] for dataset in wall_choice_probabilities])}\")\n",
    "        plt.plot(\n",
    "            wall_choice_labels, # x-coordinates\n",
    "            [dataset.ravel()[i] for dataset in wall_choice_probabilities], # y-coordinates\n",
    "            color='k',  # Get color from colormap\n",
    "            linestyle='-',  # Solid line\n",
    "            marker='x',  # Marker for the endpoints\n",
    "            linewidth=1,\n",
    "            alpha=0.4\n",
    "        )\n",
    "\n",
    "    # plt.title(\"Probability of Choosing First Wall Seen vs. First Wall Seen (Low)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(\"\")\n",
    "    plt.ylim(ylim)  # Set y-axis limits for probabilities\n",
    "    plt.gca().set_aspect(set_aspect)    \n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Remove top and bottom spines\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ratio of player performance against the ratio of probability of players choosing Low when first visible "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance_against_probability_low_when_first_visible(data_folder, json_filenames_all, correlation_line=True):\n",
    "    '''Plot the graph of session performance against session probability for players choosing low when it is first visible.\n",
    "       One data point for each session to avoid replicating data from within a session.\n",
    "       Data is taken as the ratio player0:player1 for proportion score and for probability of choice '''\n",
    "\n",
    "    # get probability of choosing the low wall when it is first visible, and the proportion of score within the session\n",
    "    # these are both recorded per player and session, shape num_sessions*num_players\n",
    "    probability_low_when_first_visible, _, _ = wall_visibility_and_choice.probability_first_wall_chosen_and_low_multiple_sessions(data_folder, json_filenames_all)\n",
    "    proportion_scores_all_sessions = get_proportion_scores(data_folder, json_filenames_all)\n",
    "\n",
    "    print(f\"Probability low when first visible: \\n {probability_low_when_first_visible}\")\n",
    "    print(f\"Proportion of scores for all sessions \\n {proportion_scores_all_sessions}\")\n",
    "\n",
    "    # from the above arrays, find the probability of choosing the low wall when it is first visible in the ratio player0:player1\n",
    "    # also find the proportion of total session score in the ratio player0:player1\n",
    "    ratio_probability_low_when_first_visible = probability_low_when_first_visible[:,0]/probability_low_when_first_visible[:,1]\n",
    "    proportion_scores_player_0 = proportion_scores_all_sessions[:,0]/proportion_scores_all_sessions[:,1] # use ratio or just player 1 proportion here?\n",
    "\n",
    "    x = ratio_probability_low_when_first_visible.ravel()\n",
    "    y = proportion_scores_player_0.ravel()\n",
    "\n",
    "    plt.scatter(x, y)\n",
    "\n",
    "    if correlation_line:\n",
    "        # Fit a line to the data\n",
    "        slope, intercept = np.polyfit(x, y, 1)  # 1st-degree polynomial (linear fit)\n",
    "        line = slope * x + intercept\n",
    "\n",
    "        # Plot the correlation line\n",
    "        plt.plot(x, line, color='red', label=f'Fit line: y = {slope:.2f}x + {intercept:.2f}')\n",
    "\n",
    "    plt.title(\"Performance in session against the probability of choosing\\n the Low wall when the Low wall is the first visible\")\n",
    "    plt.xlabel(\"Probability\")\n",
    "    plt.ylabel(\"Performance\")\n",
    "\n",
    "    # Remove top and bottom spines\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance_against_probability_low_when_first_visible(data_folder, json_filenames_all, correlation_line=True):\n",
    "    '''Plot the graph of session performance against session probability for players choosing low when it is first visible.\n",
    "       One data point for each session to avoid replicating data from within a session.\n",
    "       Data is taken as the ratio player0:player1 for proportion score and for probability of choice '''\n",
    "\n",
    "    # get probability of choosing the low wall when it is first visible, and the proportion of score within the session\n",
    "    # these are both recorded per player and session, shape num_sessions*num_players\n",
    "    probability_low_when_first_visible, _, _ = wall_visibility_and_choice.probability_first_wall_chosen_and_low_multiple_sessions_social(data_folder, json_filenames_all)\n",
    "    proportion_scores_all_sessions = get_proportion_scores(data_folder, json_filenames_all)\n",
    "\n",
    "    print(f\"Probability low when first visible: \\n {probability_low_when_first_visible}\")\n",
    "    print(f\"Proportion of scores for all sessions \\n {proportion_scores_all_sessions}\")\n",
    "\n",
    "    # from the above arrays, find the probability of choosing the low wall when it is first visible in the ratio player0:player1\n",
    "    # also find the proportion of total session score in the ratio player0:player1\n",
    "    ratio_probability_low_when_first_visible = probability_low_when_first_visible[:,0]/probability_low_when_first_visible[:,1]\n",
    "    proportion_scores_player_0 = proportion_scores_all_sessions[:,0]/proportion_scores_all_sessions[:,1] # use ratio or just player 1 proportion here?\n",
    "\n",
    "    # x = ratio_probability_low_when_first_visible.ravel()\n",
    "    x = ratio_probability_low_when_first_visible.ravel()\n",
    "    y = proportion_scores_all_sessions[:,0].ravel()\n",
    "\n",
    "    plt.scatter(x, y)\n",
    "\n",
    "    if correlation_line:\n",
    "        # Fit a line to the data\n",
    "        slope, intercept = np.polyfit(x, y, 1)  # 1st-degree polynomial (linear fit)\n",
    "        line = slope * x + intercept\n",
    "\n",
    "        # Plot the correlation line\n",
    "        plt.plot(x, line, color='red', label=f'Fit line: y = {slope:.2f}x + {intercept:.2f}')\n",
    "\n",
    "    plt.title(\"Performance in session against the probability of choosing\\n the Low wall when the Low wall is the first visible\")\n",
    "    plt.xlabel(\"Probability\")\n",
    "    plt.ylabel(\"Performance\")\n",
    "\n",
    "    # Remove top and bottom spines\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance_against_probability_low_when_first_visible_df(trial_lists, inferred_choice=False, correlation_line=True, print_correlation=True):\n",
    "    '''Plot the graph of session performance against session probability for players choosing low when it is first visible.\n",
    "       One data point for each session to avoid replicating data from within a session.\n",
    "       Data is taken as the ratio player0:player1 for probability of choice, and player0 value proportion score '''\n",
    "\n",
    "    # get probability of choosing the low wall when it is first visible, and the proportion of score within the session\n",
    "    # these are both recorded per player and session, shape num_sessions*num_players\n",
    "    probability_low_when_first_visible, _, _ = wall_visibility_and_choice.probability_first_wall_chosen_and_low_multiple_sessions_social(trial_lists, inferred_choice=inferred_choice)\n",
    "    proportion_scores_all_sessions = get_proportion_scores_df(trial_lists)\n",
    "\n",
    "    print(f\"Probability low when first visible: \\n {probability_low_when_first_visible}\")\n",
    "    print(f\"Proportion of scores for all sessions \\n {proportion_scores_all_sessions}\")\n",
    "\n",
    "    # from the above arrays, find the probability of choosing the low wall when it is first visible in the ratio player0:player1\n",
    "    # also find the proportion of total session score in the ratio player0:player1\n",
    "    ratio_probability_low_when_first_visible = probability_low_when_first_visible[:,0]/probability_low_when_first_visible[:,1]\n",
    "    proportion_scores_player_0 = proportion_scores_all_sessions[:,0]/proportion_scores_all_sessions[:,1] # use ratio or just player 1 proportion here?\n",
    "\n",
    "    # x = ratio_probability_low_when_first_visible.ravel()\n",
    "    x = ratio_probability_low_when_first_visible.ravel()\n",
    "    y = proportion_scores_all_sessions[:,0].ravel()\n",
    "\n",
    "    plt.scatter(x, y)\n",
    "\n",
    "    if correlation_line:\n",
    "        # Fit a line to the data\n",
    "        slope, intercept = np.polyfit(x, y, 1)  # 1st-degree polynomial (linear fit)\n",
    "        line = slope * x + intercept\n",
    "\n",
    "        # Plot the correlation line\n",
    "        plt.plot(x, line, color='red', label=f'Fit line: y = {slope:.2f}x + {intercept:.2f}')\n",
    "\n",
    "    if print_correlation:\n",
    "        corr_coeff_pearsonr, pval_pearsonr = pearsonr(x,y)\n",
    "        print(f\"Pearson correlation coefficient is: {corr_coeff_pearsonr}\")\n",
    "        print(f\"P-value is: {pval_pearsonr}\")\n",
    "\n",
    "    plt.title(\"Performance in session against the probability of choosing\\n the Low wall when the Low wall is the first visible\")\n",
    "    plt.xlabel(\"Probability\")\n",
    "    plt.ylabel(\"Performance\")\n",
    "\n",
    "    # Remove top and bottom spines\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for plot_performance_against_probability_low_when_first_visible\n",
    "def get_proportion_scores(data_folder, json_filenames_all):\n",
    "    ''' Returns a float array of shape num_session*num_players with the proportion of\n",
    "        total session score attributed to each player\n",
    "        Takes the data folder path string and list of filenames for JSON datasets '''\n",
    "\n",
    "    # go through every session and find the proportion of score in the session that players achieved\n",
    "    proportion_scores_all_sessions = np.zeros((len(json_filenames_all), 2))\n",
    "    \n",
    "    for json_filenames_index in range(len(json_filenames_all)):\n",
    "        # get data for session this loop index\n",
    "        json_filenames = json_filenames_all[json_filenames_index]\n",
    "        print(data_folder + os.sep + json_filenames)\n",
    "        _, trials_list = prepare_data.prepare_data(data_folder, [json_filenames])\n",
    "\n",
    "        # identify the overall session score from the final trial end log event\n",
    "        final_trial = trials_list[-1]\n",
    "        final_trial_trial_end = final_trial[final_trial['eventDescription'] == 'trial end']\n",
    "        \n",
    "        player0_score = final_trial_trial_end[globals.PLAYER_SCORE_DICT[0]['score']].item()\n",
    "        player1_score = final_trial_trial_end[globals.PLAYER_SCORE_DICT[1]['score']].item()\n",
    "        total_score = player0_score + player1_score\n",
    "        \n",
    "        # find the proportion of the total session score attributed to each player\n",
    "        proportion_score_player0 = player0_score/total_score\n",
    "        proportion_score_player1 = player1_score/total_score\n",
    "\n",
    "        proportion_scores_all_sessions[json_filenames_index, 0] = proportion_score_player0\n",
    "        proportion_scores_all_sessions[json_filenames_index, 1] = proportion_score_player1\n",
    "\n",
    "    return proportion_scores_all_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for plot_performance_against_probability_low_when_first_visible\n",
    "def get_proportion_scores_df(trial_lists):\n",
    "    ''' Returns a float array of shape num_session*num_players with the proportion of\n",
    "        total session score attributed to each player\n",
    "        Takes the data folder path string and list of filenames for JSON datasets '''\n",
    "\n",
    "    # go through every session and find the proportion of score in the session that players achieved\n",
    "    proportion_scores_all_sessions = np.zeros((len(trial_lists), 2))\n",
    "    \n",
    "    for trial_list_idx in range(len(trial_lists)):\n",
    "        # get data for session this loop index\n",
    "        trial_list = trial_lists[trial_list_idx]\n",
    "\n",
    "        # identify the overall session score from the final trial end log event\n",
    "        final_trial = trial_list[-1]\n",
    "        final_trial_trial_end = final_trial[final_trial['eventDescription'] == 'trial end']\n",
    "        \n",
    "        player0_score = final_trial_trial_end[globals.PLAYER_SCORE_DICT[0]['score']].item()\n",
    "        player1_score = final_trial_trial_end[globals.PLAYER_SCORE_DICT[1]['score']].item()\n",
    "        total_score = player0_score + player1_score\n",
    "        \n",
    "        # find the proportion of the total session score attributed to each player\n",
    "        proportion_score_player0 = player0_score/total_score\n",
    "        proportion_score_player1 = player1_score/total_score\n",
    "\n",
    "        proportion_scores_all_sessions[trial_list_idx, 0] = proportion_score_player0\n",
    "        proportion_scores_all_sessions[trial_list_idx, 1] = proportion_score_player1\n",
    "\n",
    "    return proportion_scores_all_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the probability of choosing High compared between solo and social conditions (combined and separated solo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_probability_choose_high_solo_social(social_p_choose_high, *solo_p_choose_high, black_lines=False):\n",
    "    ''' Plot paired data line graph of the probability of choosing High across\n",
    "        solo and social conditions. \n",
    "        Takes a num_sessions*num_players social array and a 1D solo array of the same size.\n",
    "        Depending on how many solo arrays are passed, will plot combined or separated solo graphs.\n",
    "        Drops points if they are nan (subject to low n in probability calculation). '''\n",
    "    \n",
    "    # convert social array to a single dimension for plotting\n",
    "    social_p_choose_high = social_p_choose_high.ravel()\n",
    "\n",
    "    # Number of individuals\n",
    "    individuals = np.arange(len(social_p_choose_high))\n",
    "\n",
    "    # Generate distinct colors for each individual\n",
    "    if black_lines:\n",
    "        colors = ['k']*len(individuals)\n",
    "    else:\n",
    "        colors = plt.cm.viridis(np.linspace(0, 1, len(individuals)))\n",
    "\n",
    "    # Plotting\n",
    "    if len(solo_p_choose_high) == 1: # plot for combined solo data\n",
    "        \n",
    "        solo_p_choose_high = solo_p_choose_high[0]\n",
    "\n",
    "        plt.figure(figsize=(4, 5))\n",
    "\n",
    "        # Plot lines for each individual\n",
    "        for i in individuals:\n",
    "\n",
    "            # check for any nan values in probabilities. Do not plot it.\n",
    "            probabilities = np.array([solo_p_choose_high[i], social_p_choose_high[i]])\n",
    "            conditions = np.array([0,1])\n",
    "            nan_mask = np.isnan(probabilities)\n",
    "            if np.any(nan_mask): # if nan value present\n",
    "                print(f\"NaN value in probabilities: {probabilities}. Dropping this point from the combined plot.\")\n",
    "            \n",
    "            plt.plot(conditions[~nan_mask], probabilities[~nan_mask], \n",
    "                    marker='o', linestyle='-', color=colors[i], alpha=0.7)\n",
    "\n",
    "        plt.plot([0,1], [np.nanmean(solo_p_choose_high), np.nanmean(social_p_choose_high)],\n",
    "                            marker='x', color='red', label='Average', linewidth=2, linestyle='--')\n",
    "\n",
    "        plt.ylabel('P(Choose High)')\n",
    "        plt.xticks([0, 1], [' Combined Solo', 'Social'])\n",
    "        plt.ylim(0, 1.1)\n",
    "        plt.gca().spines['top'].set_visible(False)\n",
    "        plt.gca().spines['right'].set_visible(False)\n",
    "        plt.show()\n",
    "\n",
    "    elif len(solo_p_choose_high) == 2: # plot for separated pre- and post solo data\n",
    "\n",
    "        solo_first_session_p_choose_high = solo_p_choose_high[0]\n",
    "        solo_second_session_p_choose_high = solo_p_choose_high[1]\n",
    "        \n",
    "        # Plotting\n",
    "        plt.figure(figsize=(6, 5))\n",
    "\n",
    "        # Plot lines for each individual\n",
    "        for i in individuals:\n",
    "\n",
    "            # check for any nan values in probabilities. Do not plot it.\n",
    "            probabilities = np.array([solo_first_session_p_choose_high[i], social_p_choose_high[i], solo_second_session_p_choose_high[i]])\n",
    "            conditions = np.array([0,1,2])\n",
    "            nan_mask = np.isnan(probabilities)\n",
    "\n",
    "            if np.any(nan_mask): # if nan value present\n",
    "                print(f\"NaN value in probabilities: {probabilities}. Dropping this point from the separated plot.\")\n",
    "\n",
    "            plt.plot(conditions[~nan_mask], probabilities[~nan_mask], \n",
    "                    marker='o', linestyle='-', color=colors[i], alpha=0.7)\n",
    "\n",
    "        plt.plot([0,1,2], [np.nanmean(solo_first_session_p_choose_high), np.nanmean(social_p_choose_high), np.nanmean(solo_second_session_p_choose_high)],\n",
    "                            marker='x', color='red', label='Average', linewidth=2, linestyle='--')\n",
    "\n",
    "        plt.ylabel('P(Choose High)')\n",
    "        plt.xticks([0, 1, 2], ['First Solo', 'Social', 'Second Solo'])\n",
    "        plt.ylim(0, 1.1)\n",
    "        plt.gca().spines['top'].set_visible(False)\n",
    "        plt.gca().spines['right'].set_visible(False)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for plot_probability_choose_high_solo_social\n",
    "def get_probability_chose_high_social_df(trial_list, trial_type=globals.HIGH_LOW, wall_sep=None):\n",
    "    ''' Find the probability that each player chose High in a social context.\n",
    "        Optionally specify the trial type and wall separation type to use.\n",
    "        This does not include inferred choices.\n",
    "        Assumes one session only. '''\n",
    "\n",
    "\n",
    "    # filter trial list to include HighLow trials only\n",
    "    if trial_type is not None:\n",
    "        trial_list_indices = get_indices.get_trials_trialtype(trial_list, trial_type=trial_type)\n",
    "        trial_list = [trial_list[i] for i in trial_list_indices]\n",
    "    # print(f\"len trial list = {len(trial_list)}\")\n",
    "\n",
    "    # filter trial list to include specific wall separation\n",
    "    if wall_sep is not None:\n",
    "        trial_list_indices =  get_indices.get_trials_with_wall_sep(trial_list, wall_sep=wall_sep)\n",
    "        trial_list = [trial_list[i] for i in trial_list_indices]\n",
    "\n",
    "    # find the high wall trials and the indices where each player won\n",
    "    high_wall_chosen = get_indices.was_high_wall_chosen(trial_list)\n",
    "    # print(f\"high_wall_chosen = {high_wall_chosen}\")\n",
    "    player0_win_indices = get_indices.get_player_win_indices(trial_list, player_id=0)\n",
    "    # print(f\"player0_win_indices = {player0_win_indices}\")\n",
    "    player1_win_indices = get_indices.get_player_win_indices(trial_list, player_id=1)\n",
    "    # print(f\"player1_win_indices = {player1_win_indices}\")\n",
    "\n",
    "    # create an array of size player_win_indices that is True where this win was a High wall choice \n",
    "    player0_wins_high = np.zeros(player0_win_indices.size)\n",
    "    for i in range(player0_win_indices.size):\n",
    "        trial_idx = player0_win_indices[i]\n",
    "        player0_wins_high[i] = True if high_wall_chosen[trial_idx] else False\n",
    "\n",
    "    player1_wins_high = np.zeros(player1_win_indices.size)\n",
    "    for i in range(player1_win_indices.size):\n",
    "        trial_idx = player1_win_indices[i]\n",
    "        player1_wins_high[i] = True if high_wall_chosen[trial_idx] else False\n",
    "\n",
    "    try:\n",
    "        probability_player0_choose_high = player0_wins_high[player0_wins_high == True].size/player0_wins_high.size\n",
    "    except ZeroDivisionError:\n",
    "        print(\"This trial list, player 0 has no wins at High\")\n",
    "        probability_player0_choose_high = np.nan\n",
    "    try:\n",
    "        probability_player1_choose_high = player1_wins_high[player1_wins_high == True].size/player1_wins_high.size\n",
    "    except ZeroDivisionError:\n",
    "        print(\"This trial list, player 1 has no wins at High\")\n",
    "        probability_player1_choose_high = np.nan\n",
    "\n",
    "    return probability_player0_choose_high, probability_player1_choose_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for plot_probability_choose_high_solo_social\n",
    "def get_probability_chose_high_solo_df(trial_list, trial_type=globals.HIGH_LOW, wall_sep=None, cut_trials=10, data_size_cutoff=4):\n",
    "    ''' Find the probability that the player chose High in a solo context\n",
    "        Takes a data folder string and JSON filename.\n",
    "        Optionally specify the trial and wall separation type to use.\n",
    "        Cut the first cut_trials trials to reduce effect of learning controls/associations. \n",
    "        Return np.nan if filtering and cut_trials leaves the trial list at size < dat_size_cutoff'''\n",
    "    \n",
    "    # cut first cut_trials trials (learning controls/associations)\n",
    "    trial_list = trial_list[cut_trials:]\n",
    "\n",
    "    # filter trial list to include HighLow trials only\n",
    "    if trial_type is not None:\n",
    "        trial_list_indices = get_indices.get_trials_trialtype(trial_list, trial_type=trial_type)\n",
    "        trial_list = [trial_list[i] for i in trial_list_indices]\n",
    "\n",
    "\n",
    "    # filter trial list to include specific wall separation\n",
    "    if wall_sep is not None:\n",
    "        trial_list_indices =  get_indices.get_trials_with_wall_sep(trial_list, wall_sep=wall_sep)\n",
    "        trial_list = [trial_list[i] for i in trial_list_indices]\n",
    "    \n",
    "    high_wall_chosen = get_indices.was_high_wall_chosen(trial_list)\n",
    "\n",
    "    # if calling this function leaves too few relevant trials, return np.nan\n",
    "    if trial_list_indices.size <= data_size_cutoff:\n",
    "        return np.nan\n",
    "    else:\n",
    "        probability_choose_high = high_wall_chosen[high_wall_chosen == True].size/trial_list_indices.size\n",
    "        return probability_choose_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for plot_probability_choose_high_solo_social\n",
    "def get_probability_chose_high_solo_social_all_sessions_df(trial_lists_solo, trial_lists_social, wall_sep=None, trial_type=globals.HIGH_LOW, cut_solo_trials=10):\n",
    "    ''' Get probabilities of choosing the High wall for each participant for each session, and split by social and solo.\n",
    "        Takes a list of trial lists for solo sessions, and for social sessions.\n",
    "        Assumes the solo trial list is complete, and that second sessions follow directly from first sessions.\n",
    "        Returns 4 floats: P(choose High) in social, combined solo, first solo session, second solo session.\n",
    "        These floats may be np.nan if low n in the probability calculation.'''\n",
    "\n",
    "\n",
    "    # 1. social\n",
    "    # loop through all social sessions\n",
    "    probability_choose_high_social_array = np.zeros((len(trial_lists_social), 2))\n",
    "    for trial_list_idx in range(len(trial_lists_social)):\n",
    "\n",
    "        # get the dataframe for this session\n",
    "        trial_list = trial_lists_social[trial_list_idx]\n",
    "\n",
    "        # find the probability of choosing high for each player\n",
    "        probability_player0_choose_high, probability_player1_choose_high = get_probability_chose_high_social_df(trial_list,\n",
    "                                                                                                        trial_type=trial_type,\n",
    "                                                                                                        wall_sep=wall_sep)\n",
    "\n",
    "        # add this to the sessions array\n",
    "        probability_choose_high_social_array[trial_list_idx,:] = [probability_player0_choose_high, probability_player1_choose_high]\n",
    "    \n",
    "    # 2. solo combined\n",
    "    # loop through all solo sessions\n",
    "    # get solo choice data for combined pre- and post-\n",
    "    probability_choose_high_solo_array = np.zeros((int(len(trial_lists_solo)/2)))\n",
    "    for trial_list_idx in range(0, len(trial_lists_solo), 2):\n",
    "\n",
    "        # concatenate the trial lists for the 2 solos of this session\n",
    "        trial_list_combined = trial_lists_solo[trial_list_idx] + trial_lists_solo[trial_list_idx + 1]\n",
    "\n",
    "        # find the probability of choosing high for each player\n",
    "        probability_choose_high = get_probability_chose_high_solo_df(trial_list_combined, trial_type=trial_type, wall_sep=wall_sep, cut_trials=cut_solo_trials)\n",
    "\n",
    "        # add this to the sessions array\n",
    "        probability_choose_high_solo_array[int(trial_list_idx/2)] = probability_choose_high\n",
    "\n",
    "    # 3. solo separated\n",
    "    # loop through all solo sessions\n",
    "    # get solo choice data for separated pre- and post\n",
    "    probability_choose_high_solo_array_separated_sessions = np.zeros(int(len(trial_lists_solo)))\n",
    "    for trial_list_idx in range(0, len(trial_lists_solo)):\n",
    "\n",
    "        # get the dataframe for this session\n",
    "        trial_list = trial_lists_solo[trial_list_idx]\n",
    "\n",
    "        # find the probability of choosing high for each player\n",
    "        probability_choose_high = get_probability_chose_high_solo_df(trial_list, trial_type=trial_type, wall_sep=wall_sep, cut_trials=cut_solo_trials)\n",
    "\n",
    "        # add this to the sessions array\n",
    "        probability_choose_high_solo_array_separated_sessions[int(trial_list_idx)] = probability_choose_high\n",
    "\n",
    "    probability_choose_high_solo_array_first_session = probability_choose_high_solo_array_separated_sessions[0::2]\n",
    "    probability_choose_high_solo_array_second_session = probability_choose_high_solo_array_separated_sessions[1::2]\n",
    "\n",
    "    \n",
    "    return (probability_choose_high_social_array, probability_choose_high_solo_array,\n",
    "            probability_choose_high_solo_array_first_session, probability_choose_high_solo_array_second_session)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More recent attempt at getting P(Choose High) in social, using up-to-date method (250116)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_trials_retrievable_choice(trial_list, player_id, inferred_choice=False):\n",
    "    ''' Return the filtered trial list and list of indices from the original trial list that\n",
    "        conform with player player_id having a recorded choice.\n",
    "        This is required for accurate probabilities, because we do cannot include trials (as negative)\n",
    "        where we do not know what the player's choice would have been. '''\n",
    "    \n",
    "    # get player choice (wall number) for each trial\n",
    "    # inferred choice can be used here\n",
    "    player_choice = wall_visibility_and_choice.get_player_wall_choice(trial_list, player_id,\n",
    "                                                                        inferred_choice, debug=False)\n",
    "    \n",
    "    print(f\"filter_trials_retrievable_choice - player_choice, inferred status {inferred_choice} is:\\n{player_choice}\")\n",
    "    \n",
    "    # filter trials list to only include trials where this player had a recorded choice\n",
    "    player_recorded_choice_indices = np.where(~np.isnan(player_choice))\n",
    "\n",
    "    # index the tuple and allow list-compatible indexing\n",
    "    player_recorded_choice_indices = player_recorded_choice_indices[0].tolist()\n",
    "\n",
    "    # Use a list comprehension to index the trial list with the indices list\n",
    "    trial_list_filtered = [trial_list[i] for i in player_recorded_choice_indices]\n",
    "\n",
    "    return trial_list_filtered, player_recorded_choice_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_probability_choose_wall(trial_list, trial_list_choice_filtered):\n",
    "    ''' Given a trial list (pre-filtered, but not for choice), calculate the probability that \n",
    "        a player will choose a given wall value as the proportion of trials from the trial\n",
    "        list in which the player chose the wall value.\n",
    "        More complex use of this function could involve e.g. filtering the trial list for \n",
    "        trials where Low was first seen and the Opponent is visible, and then further filtering\n",
    "        for player choice being 'Low', to find probability of (choose Low | first visible) under the\n",
    "        condition of Other visibility at trial start. '''\n",
    "        \n",
    "    \n",
    "    # use the length of the trial list pre-choice filtering, and the length of the trial list post-choice\n",
    "    # filtering (e.g. with filter_trials_player_chose_given_wall) to calculate the proportion of \n",
    "    # relevant trials that a player chose a specific wall\n",
    "    try:\n",
    "        probability_chose_wall = len(trial_list_choice_filtered)/len(trial_list)\n",
    "    except ZeroDivisionError:\n",
    "        probability_chose_wall = np.nan\n",
    "\n",
    "    return probability_chose_wall\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_trials_player_chose_given_wall(trial_list, player_id, given_wall_index, inferred_choice=False):\n",
    "    ''' Return a filtered trial list and list of indices from the original trial list \n",
    "        where player choice (winner + loser, or just winner) aligned with\n",
    "        the given wall index (e.g., 0 for wall1) '''\n",
    "    \n",
    "    # get player choice (wall number) for each trial\n",
    "    # inferred choice can be used here\n",
    "    player_choice = wall_visibility_and_choice.get_player_wall_choice(trial_list, player_id,\n",
    "                                                                      inferred_choice, debug=False)\n",
    "    \n",
    "    print(f\"filter_trials_player_chose_given_wall - initial player choice array:\\n{player_choice}\")\n",
    "\n",
    "    # get the truth array for whether the player choice wall aligns with the given wall parameter\n",
    "    # to this function (NB. this is NOT the wall that was eventually chosen in the trial)\n",
    "    given_wall_chosen_session = get_indices.was_given_wall_chosen(trial_list, player_choice,\n",
    "                                                                  given_wall_index)\n",
    "    \n",
    "    print(f\"given wall chosen array:\\n{given_wall_chosen_session}\")\n",
    "    \n",
    "    # find the indices of the trials in trial_list where the given wall was chosen by player player_id.\n",
    "    # this will drop trials where the given wall was not chosen, and trials without retrievable choice information\n",
    "    given_wall_chosen_indices = np.where(given_wall_chosen_session == True)\n",
    "    print(f\"given wall chosen true indices:\\n{given_wall_chosen_indices}\")\n",
    "    \n",
    "    # index the tuple and allow list-compatible indexing\n",
    "    given_wall_chosen_indices = given_wall_chosen_indices[0].tolist()\n",
    "\n",
    "    # use a list comprehension to index the trial list with the indices list\n",
    "    trial_list_filtered = [trial_list[i] for i in given_wall_chosen_indices]\n",
    "\n",
    "    # return filtered trial_list, and list of indices with which to index the original list\n",
    "    return trial_list_filtered, given_wall_chosen_indices\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_chose_high_social(trial_list, player_id,\n",
    "                                      given_wall_index=0):\n",
    "\n",
    "\n",
    "    # filter for player retrievable choice trials\n",
    "    (trial_list_filtered_choice_retrievable,\n",
    "     trial_indices_choice_retrievable) = filter_trials_retrievable_choice(trial_list,\n",
    "                                                                           player_id)\n",
    "    \n",
    "    # filter retrievable choice trials for trials where this player chose High\n",
    "    (trial_list_filtered_chose_high,\n",
    "    trial_indices_chose_high) = filter_trials_player_chose_given_wall(trial_list_filtered_choice_retrievable,\n",
    "                                                                       player_id,\n",
    "                                                                      given_wall_index)\n",
    "    \n",
    "    # calculate probability of choosing High in social for this player\n",
    "    probability_chose_high = calculate_probability_choose_wall(trial_list_filtered_choice_retrievable, trial_list_filtered_chose_high)\n",
    "\n",
    "    return probability_chose_high\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_chose_high_social_all_sessions(all_sessions, trial_type=globals.HIGH_LOW):\n",
    "\n",
    "    p_chose_high_all_sessions = np.full(len(all_sessions)*2, np.nan)\n",
    "\n",
    "    trial_list_index = 0\n",
    "    for i in range(0,len(all_sessions)*2, 2):\n",
    "\n",
    "        trial_list = all_sessions[trial_list_index]\n",
    "\n",
    "        # filter trial list for HighLow trialtype\n",
    "        trial_indices = get_indices.get_trials_trialtype(trial_list, trial_type)\n",
    "        trial_list_filtered = [trial_list[i] for i in trial_indices]\n",
    "\n",
    "        # find probability of choosing High each for player 0 and player 1\n",
    "        probability_chose_high_0 = get_probability_chose_high_social(trial_list_filtered, player_id=0)\n",
    "        probability_chose_high_1 = get_probability_chose_high_social(trial_list_filtered, player_id=1)\n",
    "        \n",
    "        p_chose_high_all_sessions[i:i+2] = probability_chose_high_0, probability_chose_high_1\n",
    "\n",
    "        trial_list_index += 1\n",
    "\n",
    "    return p_chose_high_all_sessions\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More recent attempt at getting P(Choose High) in Solo combined, using up-to-date method (250116)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability_chose_high_solo(trial_list, data_size_cutoff, player_id=0, given_wall_index=0):\n",
    "    \n",
    "    # no need to filter trials that have a retrievable choice. Any completed trial in solo\n",
    "    # will have a retrievable choice\n",
    "    \n",
    "    # filter all trials for trials where this player chose High\n",
    "    (trial_list_filtered_chose_high,\n",
    "    trial_indices_chose_high) = filter_trials_player_chose_given_wall(trial_list, player_id,\n",
    "                                                                      given_wall_index)\n",
    "    \n",
    "    # calculate probability of choosing High in social for this player\n",
    "    probability_chose_high = calculate_probability_choose_wall(trial_list, trial_list_filtered_chose_high)\n",
    "\n",
    "    # if calling this function leaves too few relevant trials, return np.nan\n",
    "    if len(trial_indices_chose_high) <= data_size_cutoff:\n",
    "\n",
    "        return np.nan\n",
    "    else:\n",
    "        \n",
    "        return probability_chose_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'HIGH_LOW'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_probability_chose_high_solo_all_sessions_combined\u001b[39m(all_sessions, trial_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHIGH_LOW\u001b[49m,\n\u001b[0;32m      2\u001b[0m                                                           cut_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, data_size_cutoff\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m):\n\u001b[0;32m      3\u001b[0m \n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# loop through all solo sessions\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m# get solo choice data for combined pre- and post-\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     probability_chose_high_all_sessions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(all_sessions)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)), np\u001b[38;5;241m.\u001b[39mnan)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m trial_list_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(all_sessions), \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m         \u001b[38;5;66;03m# concatenate the trial lists for the 2 solos of this session\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'HIGH_LOW'"
     ]
    }
   ],
   "source": [
    "def get_probability_chose_high_solo_all_sessions_combined(all_sessions, trial_type=globals.HIGH_LOW,\n",
    "                                                          cut_trials=5, data_size_cutoff=4):\n",
    "\n",
    "    # loop through all solo sessions\n",
    "    # get solo choice data for combined pre- and post-\n",
    "    probability_chose_high_all_sessions = np.full((int(len(all_sessions)/2)), np.nan)\n",
    "    for trial_list_idx in range(0, len(all_sessions), 2):\n",
    "\n",
    "        # concatenate the trial lists for the 2 solos of this session\n",
    "        trial_list_combined = all_sessions[trial_list_idx] + all_sessions[trial_list_idx + 1]\n",
    "\n",
    "        # remove the first cut_trials trials to account for learning controls/associations\n",
    "        trial_list_combined = trial_list_combined[cut_trials:]\n",
    "\n",
    "        # filter trial list for HighLow trialtype\n",
    "        trial_indices = get_indices.get_trials_trialtype(trial_list_combined, trial_type)\n",
    "        trial_list_combined_filtered = [trial_list_combined[i] for i in trial_indices]\n",
    "\n",
    "        # find the probability of choosing high for each player\n",
    "        probability_chose_high = get_probability_chose_high_solo(trial_list_combined_filtered, data_size_cutoff)\n",
    "\n",
    "        # add this to the sessions array\n",
    "        probability_chose_high_all_sessions[int(trial_list_idx/2)] = probability_chose_high\n",
    "    \n",
    "    return probability_chose_high_all_sessions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data arrays\n",
    "first_wall_seen = np.array([\n",
    "    [0.76923077, 0.75490196],\n",
    "    [0.78378378, 0.67088608],\n",
    "    [0.609375, 0.85714286],\n",
    "    [0.69911504, 0.78014184]\n",
    "])\n",
    "\n",
    "first_wall_seen_low = np.array([\n",
    "    [0.75, 0.73913043],\n",
    "    [0.86363636, 0.53846154],\n",
    "    [0.46428571, 0.82051282],\n",
    "    [0.70689655, 0.671875]\n",
    "])\n",
    "\n",
    "test_array_please_ignore = np.array([\n",
    "    [0.55, 0.34],\n",
    "    [0.34, 0.453],\n",
    "    [0.25, 0.67],\n",
    "    [0.76, 0.46]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_choice_probabilities = [first_wall_seen, first_wall_seen_low, test_array_please_ignore]\n",
    "wall_choice_labels = ['First Wall Seen', 'First Wall Seen (Low)', 'test label please ignore']\n",
    "\n",
    "# boxplot_probability_choose_wall(wall_choice_probabilities, wall_choice_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = r'D:\\Users\\Tom\\OneDrive\\PhD\\SWC\\data' # desktop home\n",
    "json_filenames_all = [r'first_experiments_2409\\240913\\2024-09-13_11-31-00_YansuJerrySocial.json',\n",
    "               r'second_experiments_2409\\240927\\2024-09-27_14-25-20_SaraEmilySocial.json',\n",
    "               r'third_experiments_2410\\241017\\2024-10-17_14-28-40_ShamirAbigailSocial.json',\n",
    "               r'fourth_experiments_2410\\241017\\2024-10-17_16-41-38_ZimoElsaSocial.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_performance_against_probability_low_when_first_visible(data_folder, json_filenames_all, correlation_line=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octagon_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
