{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97506d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from analysis import opponent_visibility, wall_visibility_and_choice\n",
    "from data_extraction import get_indices\n",
    "from plotting import plot_octagon\n",
    "from trajectory_analysis import trajectory_vectors\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f14a999",
   "metadata": {},
   "source": [
    "### Regressor value extraction functions (for one session). To be used if not loading pre-generated analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31abf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wall_sep(trial_list, normalise=False):\n",
    "    ''' Return wall separation for one session.\n",
    "        1 for 45 degrees, 2 for 90 and 4 for 180. '''\n",
    "    \n",
    "    wall_sep = np.full(len(trial_list), np.nan)\n",
    "    for i, trial in enumerate(trial_list):\n",
    "        wall_sep_this_trial = get_indices.get_wall_difference(trial=trial)\n",
    "        wall_sep[i] = wall_sep_this_trial\n",
    "\n",
    "    if normalise:\n",
    "        wall_sep = wall_sep/4\n",
    "\n",
    "    return wall_sep\n",
    "\n",
    "\n",
    "def extract_first_wall_seen(trial_list, player_id):\n",
    "    ''' Return first visible walls for one player across one session.\n",
    "        1 for WALL_1, 2 for WALL_2, np.nan for no visible wall (or both initially visible). '''\n",
    "        \n",
    "    high_wall_first_visible_session = wall_visibility_and_choice.get_given_wall_first_visible_session(trial_list,\n",
    "                                                                                                        player_id,\n",
    "                                                                                                        wall_index=0,\n",
    "                                                                                                        current_fov=110)\n",
    "\n",
    "    low_wall_first_visible_session = wall_visibility_and_choice.get_given_wall_first_visible_session(trial_list,\n",
    "                                                                                                        player_id, \n",
    "                                                                                                        wall_index=1,\n",
    "                                                                                                        current_fov=110)\n",
    "    low_wall_first_visible_session = low_wall_first_visible_session*2\n",
    "    \n",
    "    first_visible_session = high_wall_first_visible_session + low_wall_first_visible_session\n",
    "\n",
    "    first_visible_session[first_visible_session == 0] = np.nan\n",
    "\n",
    "    return first_visible_session\n",
    "\n",
    "def extract_first_wall_visibilities(trial_list, player_id, three_levels=False):\n",
    "    ''' Return first visible walls for one player across one session.\n",
    "        1 for WALL_1, 2 for WALL_2, and np.nan for no visible wall.\n",
    "        If three_levels, 1 for WALL_1, 2 for WALL_2, 3 for both visible, and np.nan for neither. '''\n",
    "\n",
    "    first_visible_session = np.full(len(trial_list), np.nan)\n",
    "    for i, trial in enumerate(trial_list):\n",
    "        wall_vis_order = wall_visibility_and_choice.get_wall_visibility_order_trial(player_id, trial, current_fov=110)\n",
    "\n",
    "        # decide whether one wall is first visible, both were initially visible, or neither wall was visible\n",
    "        # plus 1 to each index to match the wall number (1 and 2) rather than the index (0 and 1)\n",
    "        if np.all(wall_vis_order == 0): # both walls visible at the start of the trial\n",
    "            if three_levels:\n",
    "                this_trial_first_visible = wall_vis_order.size + 1\n",
    "            else:\n",
    "                this_trial_first_visible = np.nan  # optionally set both walls visible to np.nan instead of 3\n",
    "        elif np.all(np.isnan(wall_vis_order)): # neither wall visible at the start of the trial\n",
    "            this_trial_first_visible = np.nan\n",
    "        elif np.sum(wall_vis_order == 0) == 1: # one wall visible at the start of the trial\n",
    "            this_trial_first_visible = np.where(wall_vis_order == 0)[0][0] + 1\n",
    "\n",
    "        first_visible_session[i] = this_trial_first_visible\n",
    "\n",
    "    return first_visible_session\n",
    "\n",
    "# double check code\n",
    "def extract_distances_to_walls(trial_list, player_id, normalise=False):\n",
    "    ''' Return a trial_num, 2 sized array, where column 1\n",
    "        is distance to WALL_1, and column 2 is distance to WALL_2.\n",
    "        Data applies to one full session, and specified player_id.\n",
    "        If normalise, returns distances as a proportion of the maximum\n",
    "        possible in the arena '''\n",
    "    \n",
    "    # get octagon alcove coordinates\n",
    "    alcove_coordinates = plot_octagon.return_alcove_centre_points()\n",
    "\n",
    "    positions_session = np.full((len(trial_list), 2), np.nan)\n",
    "    walls_session = np.full((len(trial_list), 2), np.nan)\n",
    "    distances_session = np.full((len(trial_list), 2), np.nan)\n",
    "\n",
    "    # get distances for each trial in the session\n",
    "    for i, trial in enumerate(trial_list):\n",
    "        # get WALL_1 and WALL_2 coordinates\n",
    "        trial_walls = get_indices.get_walls(trial)\n",
    "        high_wall_idx = trial_walls[0] - 1\n",
    "        low_wall_idx = trial_walls[1] - 1\n",
    "        trial_high_coordinates = alcove_coordinates[:,high_wall_idx]\n",
    "        trial_low_coordinates = alcove_coordinates[:, low_wall_idx]\n",
    "\n",
    "        # index trajectory at timepoint 0 to get player starting coordinates\n",
    "        trajectory = trajectory_vectors.extract_trial_player_trajectory(trial=trial, player_id=player_id)\n",
    "        trial_start_position = trajectory[:,0]\n",
    "\n",
    "        # find distance between start position and WALL_1/WALL_2\n",
    "        d2h = np.linalg.norm(trial_high_coordinates - trial_start_position) # WALL_1\n",
    "        d2l = np.linalg.norm(trial_low_coordinates - trial_start_position) # WALL_2\n",
    "\n",
    "        walls_session[i,:] = trial_walls \n",
    "        positions_session[i,:] = trial_start_position\n",
    "        distances_session[i,:] = np.hstack((d2h, d2l))\n",
    "\n",
    "    # normalise to maximum possible distance in octagon\n",
    "    if normalise:\n",
    "        distances_session = distances_session/plot_octagon.return_maximum_distance()\n",
    "\n",
    "    return distances_session\n",
    "\n",
    "\n",
    "def extract_opponent_visibility_slice_onset(trial_list, player_id, current_fov=110):\n",
    "    ''' Return opponent visibility at slice onset for one player for one session.\n",
    "        1 for opponent visible, 0 for opponent not visible '''\n",
    "    \n",
    "    # slice onset angle of Other from self centre FoV\n",
    "    orientation_angle_to_other_session = opponent_visibility.get_angle_of_opponent_from_player_session(player_id, trial_list)\n",
    "\n",
    "    # boolean array of Other visible\n",
    "    other_visible_session = opponent_visibility.get_other_visible_session(orientation_angle_to_other_session, current_fov)\n",
    "    other_visible_session = other_visible_session.astype(int) # converted to int for categorical regressor\n",
    "\n",
    "    # does this return 1 and 0? \n",
    "\n",
    "    return other_visible_session\n",
    "\n",
    "\n",
    "def extract_player_choice(trial_list, player_id, inferred_choice=True, debug=True):\n",
    "    ''' Return (inferred by default) player choice for one player for one session.\n",
    "        Where inferred and actual choice are both missing, values are np.nan '''\n",
    "\n",
    "    # array of wall numbers where player choice is available, np.nan where it is not\n",
    "    player_choice = wall_visibility_and_choice.get_player_wall_choice(trial_list, player_id,\n",
    "                                                                        inferred_choice=inferred_choice, debug=debug)\n",
    "\n",
    "    # 2 where player chose High, 0 where player chose Low, np.nan where lacking inferred choice\n",
    "    high_wall_chosen_session = get_indices.was_given_wall_chosen(trial_list, player_choice,\n",
    "                                                                    given_wall_index=0)\n",
    "    high_wall_chosen_session = high_wall_chosen_session*2\n",
    "    print(f\"High wall chosen session:\\n{high_wall_chosen_session}\")\n",
    "\n",
    "    # 1 where player chose Low, 0 where player chose High, np.nan where lacking inferred choice\n",
    "    low_wall_chosen_session  = get_indices.was_given_wall_chosen(trial_list, player_choice,\n",
    "                                                                    given_wall_index=1)\n",
    "    \n",
    "    print(f\"Low wall chosen session:\\n{low_wall_chosen_session}\")\n",
    "\n",
    "    # 1 or 2 where player chose Low or High respectively, np.nan where lacking inferred choice\n",
    "    chosen_wall_session = high_wall_chosen_session + low_wall_chosen_session\n",
    "\n",
    "    print(f\"Overall chosen wall for this session:\\n{chosen_wall_session}\")\n",
    "\n",
    "    # Does this switch to 0 or 1 respectively and np.nan? \n",
    "    chosen_wall_session = chosen_wall_session -1 \n",
    "\n",
    "    return chosen_wall_session\n",
    "\n",
    "\n",
    "def extract_trial_outcome(trial_list, player_id):\n",
    "    ''' Return whether this player won the trial for one player for one session '''\n",
    "    \n",
    "    trigger_activators = get_indices.get_trigger_activators(trial_list)\n",
    "    this_player_won_session = (trigger_activators-1)*-1 if player_id == 0 else trigger_activators\n",
    "\n",
    "    return this_player_won_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd991333",
   "metadata": {},
   "source": [
    "### Analysis dictionary functions\n",
    "- Create a dictionary to hold session regressor values for each session and player\n",
    "- Populate this dictionary with regressor values\n",
    "- Save the dictionary \n",
    "- Load the dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8442336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_analysis_dict(num_experiments):\n",
    "    ''' Generate a dictionary to hold all analysis results for each player and session type.\n",
    "        This is used to store results from the GLM analysis. '''\n",
    "    \n",
    "    # Define player IDs and session types\n",
    "    player_ids = [0,1]\n",
    "\n",
    "    analysis_results = {\n",
    "        experiment_id: {\n",
    "            player_id: {\n",
    "                session_type: {\n",
    "\n",
    "                    'regressors': {\n",
    "                        'wall_sep': None,\n",
    "                        'first_seen': None,\n",
    "                        'd2h': None,\n",
    "                        'd2l': None,\n",
    "                        'opponent_visible': None,\n",
    "                        'd2h_opponent': None,\n",
    "                        'd2l_opponent': None\n",
    "                    },\n",
    "\n",
    "                    'dependent': {\n",
    "                        'choice': None\n",
    "                    },\n",
    "\n",
    "                    'misc': {\n",
    "                        'valid_trial_indices': None,\n",
    "                        'high_low_trial_indices': None\n",
    "                    }\n",
    "                    \n",
    "                }\n",
    "                for session_type in ['solo', 'social']\n",
    "            }   \n",
    "            for player_id in player_ids\n",
    "        }\n",
    "        for experiment_id in np.arange(num_experiments)\n",
    "    }\n",
    "\n",
    "    return analysis_results\n",
    "\n",
    "\n",
    "def populate_analysis_dict(analysis_results, trial_lists_social, trial_lists_combined_solo, opponent_first_seen_wall):\n",
    "    ''' Populate the analysis dictionary with data extracted from trial lists.\n",
    "        This function processes each player's trial lists, extracts relevant data,\n",
    "        and fills the analysis_results dictionary with regressors, dependent variables,\n",
    "        and miscellaneous information for both social and solo sessions. '''\n",
    "\n",
    "    # Loop through each experiment and player\n",
    "    for experiment_id, players in analysis_results.items():\n",
    "        for player_id, data in players.items():\n",
    "            \n",
    "            # get opponent_id\n",
    "            opponent_id = 1 if player_id == 0 else 0\n",
    "            \n",
    "            # get the trial lists for this session and player\n",
    "            trial_list_social = trial_lists_social[experiment_id]\n",
    "            trial_list_solo = trial_lists_combined_solo[experiment_id*2 + player_id] # player_id used to select correct solo\n",
    "            trial_lists = [trial_list_social, trial_list_solo]\n",
    "            print(f\"Trial list social length for experimentId {experiment_id} and playerId {player_id}: {len(trial_list_social)}\")\n",
    "            \n",
    "            # filter the trial lists for HighLow trials\n",
    "            original_indices_lists = []\n",
    "            for i, trial_list in enumerate(trial_lists):\n",
    "                original_indices = np.arange(len(trial_list))\n",
    "                \n",
    "                # identify indices of trial list with HighLow trials and filter\n",
    "                high_low_trial_indices = get_indices.get_trials_trialtype(trial_list, trial_type=globals.HIGH_LOW)\n",
    "                original_indices = original_indices[high_low_trial_indices]\n",
    "                trial_list_filtered = [trial_list[i] for i in high_low_trial_indices]\n",
    "                trial_lists[i] = trial_list_filtered\n",
    "                original_indices_lists.append(original_indices)\n",
    "                print(f\"{high_low_trial_indices.size} high_low_trial_indices for player_id {player_id}, trail_list {i}\\n out of {len(trial_list)} total trials\")\n",
    "\n",
    "            # re-assign trial lists\n",
    "            trial_list_social = trial_lists[0]\n",
    "            trial_list_solo = trial_lists[1]\n",
    "            \n",
    "            ## fill all social regressors\n",
    "            ## social, use player_id == player_id and trial_list_social for functions\n",
    "            # regressors social\n",
    "            player_data = analysis_results[experiment_id][player_id]['social']\n",
    "            distances = extract_distances_to_walls(trial_list_social, player_id, normalise=True)\n",
    "            distances_opponent = extract_distances_to_walls(trial_list_social, player_id=opponent_id, normalise=True)\n",
    "            player_data['regressors']['wall_sep'] = extract_wall_sep(trial_list_social, normalise=True)\n",
    "            player_data['regressors']['first_seen'] = extract_first_wall_visibilities(trial_list_social, player_id, three_levels=False)\n",
    "            player_data['regressors']['d2h'] = distances[:,0]\n",
    "            player_data['regressors']['d2l'] = distances[:,1]\n",
    "            player_data['regressors']['opponent_visible'] = extract_opponent_visibility_slice_onset(trial_list_social, player_id)\n",
    "            player_data['regressors']['d2h_opponent'] = distances_opponent[:,0]\n",
    "            player_data['regressors']['d2l_opponent'] = distances_opponent[:,1]\n",
    "            if opponent_first_seen_wall:\n",
    "                player_data['regressors']['first_seen_opponent'] = extract_first_wall_visibilities(trial_list_social, opponent_id)\n",
    "\n",
    "            # dependent variable social\n",
    "            player_data['dependent']['choice'] = extract_player_choice(trial_list_social, player_id, inferred_choice=True)\n",
    "\n",
    "            # misc\n",
    "            # player_data['misc']['valid_trial_indices'] = filtered_valid_trial_indices_social\n",
    "            player_data['misc']['high_low_trial_indices'] = original_indices_lists[0] # social trial list indices\n",
    "\n",
    "\n",
    "            ## fill all solo regressors\n",
    "            ## solo, use player_id == 0 and trial_list_solo for functions\n",
    "            # regressors solo\n",
    "            player_data = analysis_results[experiment_id][player_id]['solo']\n",
    "            distances = extract_distances_to_walls(trial_list_solo, player_id=0, normalise=True)\n",
    "            player_data['regressors']['wall_sep'] = extract_wall_sep(trial_list_solo, normalise=True)\n",
    "            player_data['regressors']['first_seen'] = extract_first_wall_visibilities(trial_list_solo, player_id=0, three_levels=False)\n",
    "            player_data['regressors']['d2h'] = distances[:,0]\n",
    "            player_data['regressors']['d2l'] = distances[:,1]\n",
    "\n",
    "            # dependent variable solo\n",
    "            player_data['dependent']['choice'] = extract_player_choice(trial_list_solo, player_id=0, inferred_choice=False) # no inferred for solo\n",
    "\n",
    "            # misc\n",
    "            player_data['misc']['high_low_trial_indices'] = original_indices_lists[1] # solo trial list indices\n",
    "\n",
    "\n",
    "    return analysis_results\n",
    "\n",
    "\n",
    "def save_analysis_dict(analysis_dict, analysis_file, analysis_dir='../data'):\n",
    "    ''' Save the analysis dictionary to a file for later use. '''\n",
    "\n",
    "    path = os.path.join(analysis_dir, analysis_file)\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(analysis_dict, f)\n",
    "\n",
    "        \n",
    "\n",
    "def load_analysis_dict(analysis_file, analysis_dir='../data'):\n",
    "    ''' Load the analysis dictionary from a file. '''\n",
    " \n",
    "    filename = os.path.join(analysis_dir, analysis_file)\n",
    "    with open(filename, 'rb') as f:\n",
    "        analysis_results = pickle.load(f)\n",
    "\n",
    "    return analysis_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c7e4f9",
   "metadata": {},
   "source": [
    "### Dataframe generation from analysis dictionary (can I reduce repeated code here?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af93f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_df_social = pd.DataFrame()\n",
    "\n",
    "for session_id, players in analysis_results.items():\n",
    "    for player_id in players:\n",
    "        \n",
    "        # take each filtered_regressor array and fill the relevant df field for this player\n",
    "        player_data = analysis_results[session_id][player_id]['social']['regressors']\n",
    "        choice = analysis_results[session_id][player_id]['social']['dependent']['choice']\n",
    "        opponent_player_id = 1 if player_id == 0 else 1\n",
    "        opponent_player_data = analysis_results[session_id][opponent_player_id]['social']['regressors']\n",
    "        df_player = pd.DataFrame(\n",
    "                    {\n",
    "                        \"SessionID\" : session_id,\n",
    "                        \"PlayerID\" : player_id,\n",
    "                        \"GlmPlayerID\" : session_id*2 + player_id,\n",
    "                        \"ChooseHigh\" : choice,\n",
    "                        \"WallSep\" : player_data['wall_sep'],\n",
    "                        \"FirstSeenWall\" : player_data['first_seen'],\n",
    "                        \"D2H\" : player_data['d2h'],\n",
    "                        \"D2L\" : player_data['d2l'],\n",
    "                        \"OpponentVisible\" : player_data['opponent_visible'],\n",
    "                        \"OpponentFirstSeenWall\" : player_data['first_seen_opponent'],\n",
    "                        \"OpponentD2H\" : player_data['d2h_opponent'],\n",
    "                        \"OpponentD2L\" : player_data['d2l_opponent']\n",
    "                        \n",
    "                    }\n",
    "        )\n",
    "\n",
    "\n",
    "        # append this smaller dataframe to the the full dataframe\n",
    "        glm_df_social = pd.concat([glm_df_social, df_player], ignore_index=True)\n",
    "\n",
    "# convert to categorical variables, retaining np.nans\n",
    "glm_df_social[\"FirstSeenWall\"] = glm_df_social[\"FirstSeenWall\"].apply(lambda x: str(x) if pd.notna(x) else x)\n",
    "glm_df_social[\"OpponentFirstSeenWall\"] = glm_df_social[\"OpponentFirstSeenWall\"].apply(lambda x: str(x) if pd.notna(x) else x)\n",
    "glm_df_social[\"FirstSeenWall\"] = glm_df_social[\"FirstSeenWall\"].astype(\"category\")\n",
    "glm_df_social[\"OpponentFirstSeenWall\"] = glm_df_social[\"OpponentFirstSeenWall\"].astype(\"category\")\n",
    "\n",
    "# glm_df_social[\"WallSep\"] = glm_df_social[\"WallSep\"].astype(\"category\") # now using continuous values for wall separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d78033",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_df_solo_social = pd.DataFrame()\n",
    "\n",
    "for session_id, players in analysis_results.items():\n",
    "    for player_id in players:\n",
    "        \n",
    "        # take each filtered_regressor array and fill the relevant df field for this player\n",
    "        player_data_solo = analysis_results[session_id][player_id]['solo']['regressors']\n",
    "        player_data_social = analysis_results[session_id][player_id]['social']['regressors']\n",
    "        choice_solo = analysis_results[session_id][player_id]['solo']['dependent']['choice']\n",
    "        choice_social = analysis_results[session_id][player_id]['social']['dependent']['choice']\n",
    "        df_player = pd.DataFrame(\n",
    "                    {\n",
    "                        \"SessionID\" : session_id,\n",
    "                        \"PlayerID\" : player_id,\n",
    "                        \"GlmPlayerID\" : session_id*2 + player_id,\n",
    "                        \"ChooseHigh\" : np.concatenate([choice_solo, choice_social]),\n",
    "                        \"WallSep\" :  np.concatenate([player_data_solo['wall_sep'], player_data_social['wall_sep']]),\n",
    "                        \"FirstSeenWall\" : np.concatenate([player_data_solo['first_seen'], player_data_social['first_seen']]),\n",
    "                        \"D2H\" : np.concatenate([player_data_solo['d2h'], player_data_social['d2h']]),\n",
    "                        \"D2L\" : np.concatenate([player_data_solo['d2l'], player_data_social['d2l']]),\n",
    "                        \"SocialContext\" : np.concatenate([np.ones(player_data_solo[\"wall_sep\"].shape[0]) - 1, np.ones(player_data_social[\"wall_sep\"].shape[0])]) # 0 for solo, 1 for social\n",
    "                    }\n",
    "        )\n",
    "\n",
    "        # append this smaller dataframe to the the full dataframe\n",
    "        glm_df_solo_social = pd.concat([glm_df_solo_social, df_player], ignore_index=True)\n",
    "\n",
    "# convert to categorical variables, retaining np.nans\n",
    "glm_df_solo_social[\"FirstSeenWall\"] = glm_df_solo_social[\"FirstSeenWall\"].apply(lambda x: str(x) if pd.notna(x) else x)\n",
    "glm_df_solo_social[\"FirstSeenWall\"] = glm_df_solo_social[\"FirstSeenWall\"].astype(\"category\")\n",
    "# glm_df_solo_social[\"WallSep\"] = glm_df_solo_social[\"WallSep\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e50439e",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_df_solo = pd.DataFrame()\n",
    "\n",
    "for session_id, players in analysis_results.items():\n",
    "    for player_id in players:\n",
    "        \n",
    "        # take each filtered_regressor array and fill the relevant df field for this player\n",
    "        player_data = analysis_results[session_id][player_id]['solo']['regressors']\n",
    "        choice = analysis_results[session_id][player_id]['solo']['dependent']['choice']\n",
    "        df_player = pd.DataFrame(\n",
    "                    {\n",
    "                        \"SessionID\" : session_id,\n",
    "                        \"PlayerID\" : player_id,\n",
    "                        \"GlmPlayerID\" : session_id*2 + player_id,\n",
    "                        \"ChooseHigh\" : choice,\n",
    "                        \"WallSep\" : player_data['wall_sep'],\n",
    "                        \"FirstSeenWall\" : player_data['first_seen'],\n",
    "                        \"D2H\" : player_data['d2h'],\n",
    "                        \"D2L\" : player_data['d2l']\n",
    "                    }\n",
    "        )\n",
    "\n",
    "        # append this smaller dataframe to the the full dataframe\n",
    "        glm_df_solo = pd.concat([glm_df_solo, df_player], ignore_index=True)\n",
    "\n",
    "# convert to categorical variables, retaining np.nans\n",
    "glm_df_solo[\"FirstSeenWall\"] = glm_df_solo[\"FirstSeenWall\"].apply(lambda x: str(x) if pd.notna(x) else x)\n",
    "glm_df_solo[\"FirstSeenWall\"] = glm_df_solo[\"FirstSeenWall\"].astype(\"category\")\n",
    "\n",
    "# glm_df_solo[\"WallSep\"] = glm_df_solo[\"WallSep\"].astype(str).astype(\"category\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
