{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4992911-7b02-448c-8ee5-c89c228ad2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import parse_data.prepare_data as prepare_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import globals\n",
    "import data_strings\n",
    "import data_extraction.get_indices as get_indices\n",
    "import analysis.wall_visibility_and_choice as wall_visibility_and_choice\n",
    "from trajectory_analysis import trajectory_vectors\n",
    "from plotting import plot_octagon\n",
    "import parse_data.identify_filepaths as identify_filepaths \n",
    "from data_extraction.trial_list_filters import filter_trials_other_visible\n",
    "from analysis import opponent_visibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a24b223",
   "metadata": {},
   "source": [
    "### Create a dataframe to feed into a GLM using D2H, D2L, First Seen, Wall Separation, and PlayerID (random effect) to predict P(Choose High)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d30f028",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = data_strings.DATA_FOLDER\n",
    "json_filenames_social, json_filenames_solo = identify_filepaths.get_filenames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7a47182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['240913_1\\\\2024-09-13_11-31-00_YW13_JL13_Social.json',\n",
       " '240927_1\\\\2024-09-27_14-25-20_SH27_EN27_Social.json',\n",
       " '241017_1\\\\2024-10-17_14-28-40_SP17_AW17_Social.json',\n",
       " '241017_2\\\\2024-10-17_16-41-38_ZH17_EM17_Social.json',\n",
       " '241112_1\\\\2024-11-12_13-31-14_KA12_WM12_Social.json',\n",
       " '241112_2\\\\2024-11-12_15-23-24_FA12_SL12_Social.json',\n",
       " '241113_1\\\\2024-11-13_14-18-54_NK13_RD13_Social.json',\n",
       " '241113_2\\\\2024-11-13_15-28-07_YL13_HC13_Social.json',\n",
       " '241119_1\\\\2024-11-19_14-24-49_AV19_XG19_Social.json',\n",
       " '241119_2\\\\2024-11-19_15-22-56_SB19_HH19_Social.json',\n",
       " '241120_1\\\\2024-11-20_14-17-44_JS20_RR20_Social.json',\n",
       " '241120_2\\\\2024-11-20_15-16-21_ZS20_VC20_Social.json',\n",
       " '241203_1\\\\2024-12-03_14-31-51_PO03_NN03_Social.json',\n",
       " '241203_2\\\\2024-12-03_15-27-28_EX03_BC03_Social.json',\n",
       " '241210_1\\\\2024-12-10_14-21-17_TE10_TK10_Social.json',\n",
       " '241210_2\\\\2024-12-10_15-20-11_RK10_RU10_Social.json',\n",
       " '241219_1\\\\2024-12-19_15-28-24_JU19_SY19_Social.json',\n",
       " '241220_1\\\\2024-12-20_17-44-50_KS20_CS20_Social.json',\n",
       " '250115_1\\\\2025-01-15_15-21-27_YY15_MR15_Social.json',\n",
       " '250115_2\\\\2025-01-15_16-27-23_YL15_RR15_Social.json',\n",
       " '250204_2\\\\2025-02-04_17-11-07_DB04_GG04_Social.json',\n",
       " '250314_1\\\\2025-03-14_12-12-57_KC14_WL14_Social.json',\n",
       " '250314_2\\\\2025-03-14_13-10-49_AE14_JL14_Social.json',\n",
       " '250314_3\\\\2025-03-14_14-24-05_MA14_RM14_Social.json',\n",
       " '250318_1\\\\2025-03-18_14-22-29_SJ18_CD18_Social.json',\n",
       " '250318_2\\\\2025-03-18_16-22-17_JK18_HL18_Social.json',\n",
       " '250318_3\\\\2025-03-18_17-27-32_HM18_SC18_Social.json',\n",
       " '250319_1\\\\2025-03-19_13-29-40_HL19_AW19_Social.json',\n",
       " '250319_2\\\\2025-03-19_14-33-16_PT19_JL19_Social.json',\n",
       " '250401_1\\\\2025-04-01_14-27-01_IS01_HQ01_Social.json',\n",
       " '250401_2\\\\2025-04-01_15-29-49_AL01_NL01_Social.json',\n",
       " '250402_1\\\\2025-04-02_16-26-25_SH02_ML02_Social.json']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_filenames_social"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c07cb011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# restrict data for testing\n",
    "json_filenames_social = json_filenames_social[:8]\n",
    "json_filenames_solo = json_filenames_solo[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "05cbba93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\240913_1\\2024-09-13_11-31-00_YW13_JL13_Social.json\n",
      "Data is from period before 2024-09-13 00:00:00\n",
      "Running dataframe through playerinfo_playerposition_conversion.\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\240927_1\\2024-09-27_14-25-20_SH27_EN27_Social.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241017_1\\2024-10-17_14-28-40_SP17_AW17_Social.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241017_2\\2024-10-17_16-41-38_ZH17_EM17_Social.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241112_1\\2024-11-12_13-31-14_KA12_WM12_Social.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241112_2\\2024-11-12_15-23-24_FA12_SL12_Social.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241113_1\\2024-11-13_14-18-54_NK13_RD13_Social.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241113_2\\2024-11-13_15-28-07_YL13_HC13_Social.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "df, trial_lists_social = prepare_data.prepare_data(data_folder, json_filenames_social, combine=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "167898aa-3073-479e-8eef-6c579c67c7f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\240913_1\\2024-09-13_11-23-37_YW13_FirstSolo.json\n",
      "Data is from period before 2024-09-13 00:00:00\n",
      "Running dataframe through playerinfo_playerposition_conversion.\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\240913_1\\2024-09-13_11-53-34_YW13_SecondSolo.json\n",
      "Data is from period before 2024-09-13 00:00:00\n",
      "Running dataframe through playerinfo_playerposition_conversion.\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\240913_1\\2024-09-13_11-23-50_JL13_FirstSolo.json\n",
      "Data is from period before 2024-09-13 00:00:00\n",
      "Running dataframe through playerinfo_playerposition_conversion.\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\240913_1\\2024-09-13_11-53-56_JL13_SecondSolo.json\n",
      "Data is from period before 2024-09-13 00:00:00\n",
      "Running dataframe through playerinfo_playerposition_conversion.\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\240927_1\\2024-09-27_14-14-31_SH27_FirstSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\240927_1\\2024-09-27_14-45-55_SH27_SecondSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\240927_1\\2024-09-27_14-14-42_EN27_FirstSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\240927_1\\2024-09-27_14-45-46_EN27_SecondSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241017_1\\2024-10-17_14-20-28_SP17_FirstSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241017_1\\2024-10-17_14-50-03_SP17_SecondSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241017_1\\2024-10-17_14-20-50_AW17_FirstSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241017_1\\2024-10-17_14-51-22_AW17_SecondSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241017_2\\2024-10-17_16-36-0_ZH17_FirstSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241017_2\\2024-10-17_17-11-46_ZH17_SecondSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241017_2\\2024-10-17_16-35-45_EM17_FirstSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241017_2\\2024-10-17_17-12-29_EM17_SecondSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241112_1\\2024-11-12_13-19-22_KA12_FirstSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241112_1\\2024-11-12_13-50-23_KA12_SecondSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241112_1\\2024-11-12_13-18-59_WM12_FirstSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241112_1\\2024-11-12_13-50-20_WM12_SecondSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241112_2\\2024-11-12_15-13-34_FA12_FirstSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241112_2\\2024-11-12_15-44-54_FA12_SecondSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241112_2\\2024-11-12_15-11-45_SL12_FirstSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241112_2\\2024-11-12_15-45-35_SL12_SecondSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241113_1\\2024-11-13_14-12-43_NK13_FirstSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241113_1\\2024-11-13_14-37-06_NK13_SecondSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241113_1\\2024-11-13_14-12-41_RD13_FirstSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241113_1\\2024-11-13_14-37-20_RD13_SecondSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241113_2\\2024-11-13_15-22-20_YL13_FirstSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241113_2\\2024-11-13_15-51-39_YL13_SecondSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241113_2\\2024-11-13_15-21-50_HC13_FirstSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\pseudonymised_json_files\\241113_2\\2024-11-13_15-51-16_HC13_SecondSolo.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "df, trial_lists_solo = prepare_data.prepare_data(data_folder, json_filenames_solo, combine=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0a8edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of combined pre- and post- social solo sessions, removing 5 trials from each pre\n",
    "trial_lists_combined_solo = []\n",
    "cut_trials = 5\n",
    "for i in range(0,len(trial_lists_solo), 2): # iterate over each individual\n",
    "    # get the trial lists for both solo sessions\n",
    "    trial_list_first_solo = trial_lists_solo[i]\n",
    "    trial_list_second_solo = trial_lists_solo[i + 1]\n",
    "\n",
    "    # cut first cut_trials trials (learning controls/associations) from the first solo\n",
    "    trial_list_first_solo = trial_list_first_solo[cut_trials:]\n",
    "\n",
    "    # combine trial lists from the first and second solo sessions (the current and consecutive index)\n",
    "    trial_list = trial_list_first_solo + trial_list_second_solo\n",
    "\n",
    "    trial_lists_combined_solo.append(trial_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4890fa3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 8)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial_lists_combined_solo), len(trial_lists_social)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46092b8",
   "metadata": {},
   "source": [
    "### Regressor value extraction functions (for one session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78024b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wall_sep(trial_list):\n",
    "    ''' Return wall separation for one session '''\n",
    "    \n",
    "    wall_sep = np.full(len(trial_list), np.nan)\n",
    "    for i, trial in enumerate(trial_list):\n",
    "        wall_sep_this_trial = get_indices.get_wall_difference(trial=trial)\n",
    "        wall_sep[i] = wall_sep_this_trial\n",
    "\n",
    "    return wall_sep\n",
    "\n",
    "\n",
    "def extract_first_wall_seen(trial_list, player_id):\n",
    "    ''' Return first visible walls for one player across one session.\n",
    "        1 for WALL_1, 2 for WALL_2, np.nan for no visible wall (or both initially visible) '''\n",
    "        \n",
    "    high_wall_first_visible_session = wall_visibility_and_choice.get_given_wall_first_visible_session(trial_list,\n",
    "                                                                                                        player_id,\n",
    "                                                                                                        wall_index=0,\n",
    "                                                                                                        current_fov=110)\n",
    "\n",
    "    low_wall_first_visible_session = wall_visibility_and_choice.get_given_wall_first_visible_session(trial_list,\n",
    "                                                                                                        player_id, \n",
    "                                                                                                        wall_index=1,\n",
    "                                                                                                        current_fov=110)\n",
    "    low_wall_first_visible_session = low_wall_first_visible_session*2\n",
    "    \n",
    "    first_visible_session = high_wall_first_visible_session + low_wall_first_visible_session\n",
    "\n",
    "    first_visible_session[first_visible_session == 0] = np.nan\n",
    "\n",
    "    return first_visible_session\n",
    "\n",
    "# double check code\n",
    "def extract_distances_to_walls(trial_list, player_id):\n",
    "    ''' Return a trial_num, 2 sized array, where column 1\n",
    "        is distance to WALL_1, and column 2 is distance to WALL_2.\n",
    "        Data applies to one full session, and specified player_id'''\n",
    "    \n",
    "    # get octagon alcove coordinates\n",
    "    alcove_coordinates = plot_octagon.return_alcove_centre_points()\n",
    "\n",
    "    positions_session = np.full((len(trial_list), 2), np.nan)\n",
    "    walls_session = np.full((len(trial_list), 2), np.nan)\n",
    "    distances_session = np.full((len(trial_list), 2), np.nan)\n",
    "\n",
    "    # get distances for each trial in the session\n",
    "    for i, trial in enumerate(trial_list):\n",
    "        # get WALL_1 and WALL_2 coordinates\n",
    "        trial_walls = get_indices.get_walls(trial)\n",
    "        high_wall_idx = trial_walls[0] - 1\n",
    "        low_wall_idx = trial_walls[1] - 1\n",
    "        trial_high_coordinates = alcove_coordinates[:,high_wall_idx]\n",
    "        trial_low_coordinates = alcove_coordinates[:, low_wall_idx]\n",
    "\n",
    "        # index trajectory at timepoint 0 to get player starting coordinates\n",
    "        trajectory = trajectory_vectors.extract_trial_player_trajectory(trial=trial, player_id=player_id)\n",
    "        trial_start_position = trajectory[:,0]\n",
    "\n",
    "        # find distance between start position and WALL_1/WALL_2\n",
    "        d2h = np.linalg.norm(trial_high_coordinates - trial_start_position) # WALL_1\n",
    "        d2l = np.linalg.norm(trial_low_coordinates - trial_start_position) # WALL_2\n",
    "\n",
    "        walls_session[i,:] = trial_walls \n",
    "        positions_session[i,:] = trial_start_position\n",
    "        distances_session[i,:] = np.hstack((d2h, d2l))\n",
    "\n",
    "    return distances_session\n",
    "\n",
    "\n",
    "def extract_opponent_visibility_slice_onset(trial_list, player_id, current_fov=110):\n",
    "    ''' Return opponent visibility at slice onset for one player for one session '''\n",
    "    \n",
    "    # slice onset angle of Other from self centre FoV\n",
    "    orientation_angle_to_other_session = opponent_visibility.get_angle_of_opponent_from_player_session(player_id, trial_list)\n",
    "\n",
    "    # boolean array of Other visible\n",
    "    other_visible_session = opponent_visibility.get_other_visible_session(orientation_angle_to_other_session, current_fov)\n",
    "    other_visible_session = other_visible_session.astype(int) # converted to int for categorical regressor\n",
    "\n",
    "    return other_visible_session\n",
    "\n",
    "\n",
    "def extract_player_choice(trial_list, player_id, inferred_choice=True):\n",
    "    ''' Return (inferred by default) player choice for one player for one session.\n",
    "        Where inferred and actual choice are both missing, values are np.nan '''\n",
    "\n",
    "    # array of wall numbers where player won, np.nan where player did not\n",
    "    player_choice = wall_visibility_and_choice.get_player_wall_choice(trial_list, player_id,\n",
    "                                                                        inferred_choice=inferred_choice, debug=False)\n",
    "\n",
    "    # 2 where player chose High, 0 where player chose Low, np.nan where player lost\n",
    "    high_wall_chosen_session = get_indices.was_given_wall_chosen(trial_list, player_choice,\n",
    "                                                                    given_wall_index=0)\n",
    "    high_wall_chosen_session = high_wall_chosen_session*2\n",
    "\n",
    "    # 1 where player chose Low, 0 where player chose High, np.nan where player lost\n",
    "    low_wall_chosen_session  = get_indices.was_given_wall_chosen(trial_list, player_choice,\n",
    "                                                                    given_wall_index=1)\n",
    "\n",
    "    # 1 or 2 where player chose Low or High respectively, np.nan where player lost\n",
    "    chosen_wall_session = high_wall_chosen_session + low_wall_chosen_session\n",
    "\n",
    "    return chosen_wall_session\n",
    "\n",
    "\n",
    "def extract_trial_outcome(trial_list, player_id):\n",
    "    ''' Return whether this player won the trial for one player for one session '''\n",
    "    \n",
    "    trigger_activators = get_indices.get_trigger_activators(trial_list)\n",
    "    this_player_won_session = (trigger_activators-1)*-1 if player_id == 0 else trigger_activators\n",
    "\n",
    "    return this_player_won_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65114032",
   "metadata": {},
   "source": [
    "### Extract 1D arrays for each player for the regressor values (Sandbox, applied to a single trial list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "79718498",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_list = trial_lists_social[6]\n",
    "trial_indices = get_indices.get_trials_trialtype(trial_list, trial_type=globals.HIGH_LOW)\n",
    "trial_list = [trial_list[i] for i in trial_indices]\n",
    "player_id = 0\n",
    "current_fov = 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "883e3867",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab068cf",
   "metadata": {},
   "source": [
    "#### Wall Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d312f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wall_sep = np.full(len(trial_list), np.nan)\n",
    "for i, trial in enumerate(trial_list):\n",
    "    wall_sep_this_trial = get_indices.get_wall_difference(trial=trial)\n",
    "    wall_sep[i] = wall_sep_this_trial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea032ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3157894736842105"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(wall_sep == 4)/np.count_nonzero(wall_sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad36678b",
   "metadata": {},
   "source": [
    "#### First Seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f750de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "high_wall_first_visible_session = wall_visibility_and_choice.get_given_wall_first_visible_session(trial_list,\n",
    "                                                                                                    player_id,\n",
    "                                                                                                    wall_index=0,\n",
    "                                                                                                    current_fov=110)\n",
    "\n",
    "low_wall_first_visible_session = wall_visibility_and_choice.get_given_wall_first_visible_session(trial_list,\n",
    "                                                                                                     player_id, \n",
    "                                                                                                     wall_index=1,\n",
    "                                                                                                     current_fov=110)\n",
    "low_wall_first_visible_session = low_wall_first_visible_session*2\n",
    "\n",
    "\n",
    "\n",
    "first_visible_session = high_wall_first_visible_session + low_wall_first_visible_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0a8e860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 1., 2., 0., 0., 2., 1., 1., 1., 2., 2., 1., 1., 2., 2., 2.,\n",
       "       2., 2., 1., 1., 0., 0., 2., 2., 0., 2., 2., 1., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 0., 1., 1., 2., 2., 0., 2., 1., 0., 0., 2., 2., 1., 0., 2.,\n",
       "       2., 0., 2., 0., 0., 1., 1., 1., 1., 2., 2., 2., 2., 1., 2., 2., 2.,\n",
       "       2., 1., 1., 1., 1., 1., 2., 2., 2., 1., 2., 2., 0., 2., 1., 1., 2.,\n",
       "       2., 2., 2., 1., 1., 0., 2., 2., 2., 1., 1., 2., 1., 1., 0., 2., 1.,\n",
       "       1., 2., 1., 2., 2., 2., 2., 1., 1., 2., 1., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_visible_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf06370",
   "metadata": {},
   "source": [
    "#### Distance to High, Low\n",
    "(Check code validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67242f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get octagon alcove coordinates\n",
    "alcove_coordinates = plot_octagon.return_alcove_centre_points()\n",
    "\n",
    "start_positions = np.full((len(trial_list), 2), np.nan)\n",
    "session_walls = np.full((len(trial_list), 2), np.nan)\n",
    "distances = np.full((len(trial_list), 2), np.nan)\n",
    "\n",
    "# get distances for each trial in the session\n",
    "for i, trial in enumerate(trial_list):\n",
    "    # get WALL_1 and WALL_2 for each trial in the session\n",
    "    trial_walls = get_indices.get_walls(trial)\n",
    "    high_wall_idx = trial_walls[0] - 1\n",
    "    low_wall_idx = trial_walls[1] - 1\n",
    "    trial_high_coordinates = alcove_coordinates[:,high_wall_idx]\n",
    "    trial_low_coordinates = alcove_coordinates[:, low_wall_idx]\n",
    "\n",
    "    # index trajectory at timepoint 0 to get starting position\n",
    "    trajectory = trajectory_vectors.extract_trial_player_trajectory(trial=trial, player_id=player_id)\n",
    "    trial_start_position = trajectory[:,0]\n",
    "\n",
    "    # find distance between start position and WALL_1/WALL_2\n",
    "    d2h = np.linalg.norm(trial_high_coordinates - trial_start_position) # WALL_1\n",
    "    d2l = np.linalg.norm(trial_low_coordinates - trial_start_position)\n",
    "\n",
    "    session_walls[i,:] = trial_walls \n",
    "    start_positions[i,:] = trial_start_position\n",
    "    distances[i,:] = np.hstack((d2h, d2l))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9f7c1d",
   "metadata": {},
   "source": [
    "#### Opponent visibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3a1dfdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice onset angle of Other from self centre FoV\n",
    "orientation_angle_to_other_session = opponent_visibility.get_angle_of_opponent_from_player_session(player_id, trial_list)\n",
    "\n",
    "# boolean array of Other visible\n",
    "other_visible_session = opponent_visibility.get_other_visible_session(orientation_angle_to_other_session, current_fov)\n",
    "other_visible_session = other_visible_session.astype(int) # converted to int for categorical regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "7b23b289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_visible_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6af099b",
   "metadata": {},
   "source": [
    "#### Player choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4bdfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# array of wall numbers where player choice is confident, np.nan where player lost and choice is unconfident\n",
    "player_choice = wall_visibility_and_choice.get_player_wall_choice(trial_list, player_id,\n",
    "                                                                    inferred_choice=True, debug=False)\n",
    "\n",
    "# 2 where player chose High, 0 where player chose Low, np.nan where player lost\n",
    "high_wall_chosen_session = get_indices.was_given_wall_chosen(trial_list, player_choice,\n",
    "                                                                given_wall_index=0)\n",
    "high_wall_chosen_session = high_wall_chosen_session*2\n",
    "\n",
    "# 1 where player chose Low, 0 where player chose High, np.nan where player lost\n",
    "low_wall_chosen_session  = get_indices.was_given_wall_chosen(trial_list, player_choice,\n",
    "                                                                given_wall_index=1)\n",
    "\n",
    "# 1 or 2 where player chose Low or High respectively, np.nan where player lost\n",
    "chosen_wall_session_wins_and_losses = high_wall_chosen_session + low_wall_chosen_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029bb240",
   "metadata": {},
   "source": [
    "### Filter trials to only include those with full information for the GLM \n",
    "- Remove trials without recorded choice (np.nan in choice array) (whether I'm using inferred-choice or not)\n",
    "- Remove trials without a first visible wall (np.nan in first seen array)\n",
    "- Filter HighLow trials initially\n",
    "\n",
    "The best way to do the above may be to keep an array of 'original indices', filter this array in the same way as I do my normal trial list filtering, and then I have an indices array with preserved numbering that I can use to index valid trials to add to my dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "81bc1a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(82)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(one_wall_first_visible_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ed7d4197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(87)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(retrievable_choice_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "8438e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify indices of trial list with HighLow trials\n",
    "high_low_trial_indices = get_indices.get_trials_trialtype(trial_list, trial_type=globals.HIGH_LOW)\n",
    "\n",
    "# get choice and first visible wall data for one player, session\n",
    "player_choice_session = extract_player_choice(trial_list, player_id)\n",
    "first_wall_seen_session = extract_first_wall_seen(trial_list, player_id)\n",
    "\n",
    "\n",
    "# apply masks for one visible wall and a retrievable choice to the set of HighLow trials\n",
    "retrievable_choice_mask = ~np.isnan(player_choice_session[high_low_trial_indices])\n",
    "one_wall_first_visible_mask = ~np.isnan(first_wall_seen_session[high_low_trial_indices])\n",
    "\n",
    "# combine masks into one \n",
    "final_mask = retrievable_choice_mask & one_wall_first_visible_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b82f3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_indices = high_low_trial_indices[final_mask]\n",
    "filtered_trials = [trial_list[i] for i in filtered_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53652f8c",
   "metadata": {},
   "source": [
    "#### Filtering function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "211a5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_valid_trial_indices(trial_list, player_id, solo=False):\n",
    "    ''' Return the indices of a filtered trial list that correspond to trials in which there is a \n",
    "        retrievable choice and an identifiable first seen wall.'''\n",
    "\n",
    "    # identify indices of trial list with HighLow trials\n",
    "    high_low_trial_indices = get_indices.get_trials_trialtype(trial_list, trial_type=globals.HIGH_LOW)\n",
    "\n",
    "    print(f\"{high_low_trial_indices.size} high_low_trial_indices for player_id {player_id}\")\n",
    "\n",
    "\n",
    "    # get choice and first visible wall data for one player, session\n",
    "    if not solo:\n",
    "        player_choice_session = extract_player_choice(trial_list, player_id)\n",
    "    else:\n",
    "        player_choice_session = extract_player_choice(trial_list, player_id, inferred_choice=False)\n",
    "    \n",
    "    first_wall_seen_session = extract_first_wall_seen(trial_list, player_id)\n",
    "\n",
    "    # apply masks for one visible wall and a retrievable choice to the set of HighLow trials\n",
    "    retrievable_choice_mask = ~np.isnan(player_choice_session[high_low_trial_indices])\n",
    "\n",
    "    print(f\"{np.sum(retrievable_choice_mask)} retrievable choices for player_id {player_id}\")\n",
    "\n",
    "    one_wall_first_visible_mask = ~np.isnan(first_wall_seen_session[high_low_trial_indices])\n",
    "\n",
    "    print(f\"{np.sum(one_wall_first_visible_mask)} first visible walls for player_id {player_id}\")\n",
    "\n",
    "\n",
    "    # combine masks\n",
    "    final_mask = retrievable_choice_mask & one_wall_first_visible_mask\n",
    "\n",
    "    # filter the trial list indices based on masks\n",
    "    filtered_indices = high_low_trial_indices[final_mask]\n",
    "\n",
    "    assert filtered_indices.size > 0\n",
    "    \n",
    "    print(f\"{filtered_indices.size} filtered trials for player_id {player_id}\")\n",
    "    \n",
    "    return filtered_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d1d09b",
   "metadata": {},
   "source": [
    "### Create a dictionary to hold, for each session and player, regressor values for the session, only including trials with fully-populated regessors\n",
    "- Fields for each of the regressors applied to all trials\n",
    "- Fields for each of the regressors with only valid trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1d70320",
   "metadata": {},
   "outputs": [],
   "source": [
    "solo = False\n",
    "player_ids = [0] if solo else [0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "725c0ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results = {\n",
    "    experiment_id: {\n",
    "        player_id: {\n",
    "            session_type: {\n",
    "\n",
    "                'regressors': {\n",
    "                    'wall_sep': None,\n",
    "                    'first_seen': None,\n",
    "                    'd2h': None,\n",
    "                    'd2l': None,\n",
    "                    'opponent_visible': None,\n",
    "                },\n",
    "\n",
    "                'dependent': {\n",
    "                    'choice': None\n",
    "                }\n",
    "                \n",
    "            }\n",
    "            for session_type in ['solo', 'social']\n",
    "        }   \n",
    "        for player_id in player_ids\n",
    "    }\n",
    "    for experiment_id in np.arange(len(trial_lists_social))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b678b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results_solo = {\n",
    "    session_id: {\n",
    "        player_id: {\n",
    "\n",
    "            # unfiltered regressors\n",
    "            'regressors': {\n",
    "                'wall_sep': None,\n",
    "                'first_seen': None,\n",
    "                'd2h': None,\n",
    "                'd2l': None,\n",
    "                'opponent_visible': None,\n",
    "            },\n",
    "\n",
    "            # regressors filtered for trials fully-populated regressor values\n",
    "            'regressors_filtered': {\n",
    "                'wall_sep': None,\n",
    "                'first_seen': None,\n",
    "                'd2h': None,\n",
    "                'd2l': None,\n",
    "                'opponent_visible': None,\n",
    "            },\n",
    "\n",
    "            'dependent': {\n",
    "                'choice': None\n",
    "            }\n",
    "\n",
    "        }\n",
    "        for player_id in player_ids\n",
    "    }\n",
    "    for session_id in np.arange(len(trial_lists_social))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a932ecf8",
   "metadata": {},
   "source": [
    "### Populate the dictionary with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d364c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_choice = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "56952ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(analysis_results[14][1]['regressors_filtered']['outcome'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "94af603e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial_lists_solo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad46266b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "da5fe601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_results[0][1]['social']['dependent']['outcome'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c173632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial list social length for experimentId 0 and playerId 0: 129\n",
      "102 high_low_trial_indices for player_id 0\n",
      "82 retrievable choices for player_id 0\n",
      "82 first visible walls for player_id 0\n",
      "66 filtered trials for player_id 0\n",
      "52 high_low_trial_indices for player_id 0\n",
      "52 retrievable choices for player_id 0\n",
      "38 first visible walls for player_id 0\n",
      "38 filtered trials for player_id 0\n",
      "Trial list social length for experimentId 0 and playerId 1: 129\n",
      "102 high_low_trial_indices for player_id 1\n",
      "96 retrievable choices for player_id 1\n",
      "84 first visible walls for player_id 1\n",
      "78 filtered trials for player_id 1\n",
      "51 high_low_trial_indices for player_id 0\n",
      "51 retrievable choices for player_id 0\n",
      "44 first visible walls for player_id 0\n",
      "44 filtered trials for player_id 0\n",
      "Trial list social length for experimentId 1 and playerId 0: 104\n",
      "79 high_low_trial_indices for player_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomha\\repos\\octagon_analysis\\trajectory_analysis\\trajectory_vectors.py:321: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cosine_similarity_this_wall = dot_product[wall_num]/(player_to_alcove_vector_norms[wall_num] * player_vector_norm)\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:47: RuntimeWarning: Mean of empty slice\n",
      "  return np.argmax(np.nanmean(cosine_similarity_trajectory, axis=1))\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:149: RuntimeWarning: Mean of empty slice\n",
      "  highest_alignment_val = np.max(np.nanmean(cosine_similarity_trajectory, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48 retrievable choices for player_id 0\n",
      "50 first visible walls for player_id 0\n",
      "30 filtered trials for player_id 0\n",
      "52 high_low_trial_indices for player_id 0\n",
      "52 retrievable choices for player_id 0\n",
      "45 first visible walls for player_id 0\n",
      "45 filtered trials for player_id 0\n",
      "Trial list social length for experimentId 1 and playerId 1: 104\n",
      "79 high_low_trial_indices for player_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomha\\repos\\octagon_analysis\\trajectory_analysis\\trajectory_vectors.py:321: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cosine_similarity_this_wall = dot_product[wall_num]/(player_to_alcove_vector_norms[wall_num] * player_vector_norm)\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:47: RuntimeWarning: Mean of empty slice\n",
      "  return np.argmax(np.nanmean(cosine_similarity_trajectory, axis=1))\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:149: RuntimeWarning: Mean of empty slice\n",
      "  highest_alignment_val = np.max(np.nanmean(cosine_similarity_trajectory, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 retrievable choices for player_id 1\n",
      "59 first visible walls for player_id 1\n",
      "59 filtered trials for player_id 1\n",
      "50 high_low_trial_indices for player_id 0\n",
      "50 retrievable choices for player_id 0\n",
      "45 first visible walls for player_id 0\n",
      "45 filtered trials for player_id 0\n",
      "Trial list social length for experimentId 2 and playerId 0: 111\n",
      "93 high_low_trial_indices for player_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomha\\repos\\octagon_analysis\\trajectory_analysis\\trajectory_vectors.py:321: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cosine_similarity_this_wall = dot_product[wall_num]/(player_to_alcove_vector_norms[wall_num] * player_vector_norm)\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:47: RuntimeWarning: Mean of empty slice\n",
      "  return np.argmax(np.nanmean(cosine_similarity_trajectory, axis=1))\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:149: RuntimeWarning: Mean of empty slice\n",
      "  highest_alignment_val = np.max(np.nanmean(cosine_similarity_trajectory, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 retrievable choices for player_id 0\n",
      "66 first visible walls for player_id 0\n",
      "51 filtered trials for player_id 0\n",
      "39 high_low_trial_indices for player_id 0\n",
      "39 retrievable choices for player_id 0\n",
      "31 first visible walls for player_id 0\n",
      "31 filtered trials for player_id 0\n",
      "Trial list social length for experimentId 2 and playerId 1: 111\n",
      "93 high_low_trial_indices for player_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomha\\repos\\octagon_analysis\\trajectory_analysis\\trajectory_vectors.py:321: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cosine_similarity_this_wall = dot_product[wall_num]/(player_to_alcove_vector_norms[wall_num] * player_vector_norm)\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:47: RuntimeWarning: Mean of empty slice\n",
      "  return np.argmax(np.nanmean(cosine_similarity_trajectory, axis=1))\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:149: RuntimeWarning: Mean of empty slice\n",
      "  highest_alignment_val = np.max(np.nanmean(cosine_similarity_trajectory, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 retrievable choices for player_id 1\n",
      "69 first visible walls for player_id 1\n",
      "61 filtered trials for player_id 1\n",
      "50 high_low_trial_indices for player_id 0\n",
      "50 retrievable choices for player_id 0\n",
      "39 first visible walls for player_id 0\n",
      "39 filtered trials for player_id 0\n",
      "Trial list social length for experimentId 3 and playerId 0: 176\n",
      "136 high_low_trial_indices for player_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomha\\repos\\octagon_analysis\\trajectory_analysis\\trajectory_vectors.py:321: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cosine_similarity_this_wall = dot_product[wall_num]/(player_to_alcove_vector_norms[wall_num] * player_vector_norm)\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:47: RuntimeWarning: Mean of empty slice\n",
      "  return np.argmax(np.nanmean(cosine_similarity_trajectory, axis=1))\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:149: RuntimeWarning: Mean of empty slice\n",
      "  highest_alignment_val = np.max(np.nanmean(cosine_similarity_trajectory, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 retrievable choices for player_id 0\n",
      "118 first visible walls for player_id 0\n",
      "89 filtered trials for player_id 0\n",
      "56 high_low_trial_indices for player_id 0\n",
      "56 retrievable choices for player_id 0\n",
      "46 first visible walls for player_id 0\n",
      "46 filtered trials for player_id 0\n",
      "Trial list social length for experimentId 3 and playerId 1: 176\n",
      "136 high_low_trial_indices for player_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomha\\repos\\octagon_analysis\\trajectory_analysis\\trajectory_vectors.py:321: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cosine_similarity_this_wall = dot_product[wall_num]/(player_to_alcove_vector_norms[wall_num] * player_vector_norm)\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:47: RuntimeWarning: Mean of empty slice\n",
      "  return np.argmax(np.nanmean(cosine_similarity_trajectory, axis=1))\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:149: RuntimeWarning: Mean of empty slice\n",
      "  highest_alignment_val = np.max(np.nanmean(cosine_similarity_trajectory, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 retrievable choices for player_id 1\n",
      "115 first visible walls for player_id 1\n",
      "109 filtered trials for player_id 1\n",
      "67 high_low_trial_indices for player_id 0\n",
      "67 retrievable choices for player_id 0\n",
      "51 first visible walls for player_id 0\n",
      "51 filtered trials for player_id 0\n",
      "Trial list social length for experimentId 4 and playerId 0: 101\n",
      "77 high_low_trial_indices for player_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomha\\repos\\octagon_analysis\\trajectory_analysis\\trajectory_vectors.py:321: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cosine_similarity_this_wall = dot_product[wall_num]/(player_to_alcove_vector_norms[wall_num] * player_vector_norm)\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:47: RuntimeWarning: Mean of empty slice\n",
      "  return np.argmax(np.nanmean(cosine_similarity_trajectory, axis=1))\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:149: RuntimeWarning: Mean of empty slice\n",
      "  highest_alignment_val = np.max(np.nanmean(cosine_similarity_trajectory, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 retrievable choices for player_id 0\n",
      "36 first visible walls for player_id 0\n",
      "23 filtered trials for player_id 0\n",
      "56 high_low_trial_indices for player_id 0\n",
      "56 retrievable choices for player_id 0\n",
      "29 first visible walls for player_id 0\n",
      "29 filtered trials for player_id 0\n",
      "Trial list social length for experimentId 4 and playerId 1: 101\n",
      "77 high_low_trial_indices for player_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomha\\repos\\octagon_analysis\\trajectory_analysis\\trajectory_vectors.py:321: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cosine_similarity_this_wall = dot_product[wall_num]/(player_to_alcove_vector_norms[wall_num] * player_vector_norm)\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:47: RuntimeWarning: Mean of empty slice\n",
      "  return np.argmax(np.nanmean(cosine_similarity_trajectory, axis=1))\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:149: RuntimeWarning: Mean of empty slice\n",
      "  highest_alignment_val = np.max(np.nanmean(cosine_similarity_trajectory, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 retrievable choices for player_id 1\n",
      "58 first visible walls for player_id 1\n",
      "47 filtered trials for player_id 1\n",
      "51 high_low_trial_indices for player_id 0\n",
      "51 retrievable choices for player_id 0\n",
      "39 first visible walls for player_id 0\n",
      "39 filtered trials for player_id 0\n",
      "Trial list social length for experimentId 5 and playerId 0: 122\n",
      "93 high_low_trial_indices for player_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomha\\repos\\octagon_analysis\\trajectory_analysis\\trajectory_vectors.py:321: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cosine_similarity_this_wall = dot_product[wall_num]/(player_to_alcove_vector_norms[wall_num] * player_vector_norm)\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:47: RuntimeWarning: Mean of empty slice\n",
      "  return np.argmax(np.nanmean(cosine_similarity_trajectory, axis=1))\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:149: RuntimeWarning: Mean of empty slice\n",
      "  highest_alignment_val = np.max(np.nanmean(cosine_similarity_trajectory, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 retrievable choices for player_id 0\n",
      "71 first visible walls for player_id 0\n",
      "69 filtered trials for player_id 0\n",
      "77 high_low_trial_indices for player_id 0\n",
      "77 retrievable choices for player_id 0\n",
      "58 first visible walls for player_id 0\n",
      "58 filtered trials for player_id 0\n",
      "Trial list social length for experimentId 5 and playerId 1: 122\n",
      "93 high_low_trial_indices for player_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomha\\repos\\octagon_analysis\\trajectory_analysis\\trajectory_vectors.py:321: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cosine_similarity_this_wall = dot_product[wall_num]/(player_to_alcove_vector_norms[wall_num] * player_vector_norm)\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:47: RuntimeWarning: Mean of empty slice\n",
      "  return np.argmax(np.nanmean(cosine_similarity_trajectory, axis=1))\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:149: RuntimeWarning: Mean of empty slice\n",
      "  highest_alignment_val = np.max(np.nanmean(cosine_similarity_trajectory, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75 retrievable choices for player_id 1\n",
      "64 first visible walls for player_id 1\n",
      "54 filtered trials for player_id 1\n",
      "76 high_low_trial_indices for player_id 0\n",
      "76 retrievable choices for player_id 0\n",
      "54 first visible walls for player_id 0\n",
      "54 filtered trials for player_id 0\n",
      "Trial list social length for experimentId 6 and playerId 0: 114\n",
      "93 high_low_trial_indices for player_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomha\\repos\\octagon_analysis\\trajectory_analysis\\trajectory_vectors.py:321: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cosine_similarity_this_wall = dot_product[wall_num]/(player_to_alcove_vector_norms[wall_num] * player_vector_norm)\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:47: RuntimeWarning: Mean of empty slice\n",
      "  return np.argmax(np.nanmean(cosine_similarity_trajectory, axis=1))\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:149: RuntimeWarning: Mean of empty slice\n",
      "  highest_alignment_val = np.max(np.nanmean(cosine_similarity_trajectory, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87 retrievable choices for player_id 0\n",
      "82 first visible walls for player_id 0\n",
      "76 filtered trials for player_id 0\n",
      "39 high_low_trial_indices for player_id 0\n",
      "39 retrievable choices for player_id 0\n",
      "27 first visible walls for player_id 0\n",
      "27 filtered trials for player_id 0\n",
      "Trial list social length for experimentId 6 and playerId 1: 114\n",
      "93 high_low_trial_indices for player_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomha\\repos\\octagon_analysis\\trajectory_analysis\\trajectory_vectors.py:321: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cosine_similarity_this_wall = dot_product[wall_num]/(player_to_alcove_vector_norms[wall_num] * player_vector_norm)\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:47: RuntimeWarning: Mean of empty slice\n",
      "  return np.argmax(np.nanmean(cosine_similarity_trajectory, axis=1))\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:149: RuntimeWarning: Mean of empty slice\n",
      "  highest_alignment_val = np.max(np.nanmean(cosine_similarity_trajectory, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92 retrievable choices for player_id 1\n",
      "76 first visible walls for player_id 1\n",
      "75 filtered trials for player_id 1\n",
      "46 high_low_trial_indices for player_id 0\n",
      "46 retrievable choices for player_id 0\n",
      "39 first visible walls for player_id 0\n",
      "39 filtered trials for player_id 0\n",
      "Trial list social length for experimentId 7 and playerId 0: 134\n",
      "109 high_low_trial_indices for player_id 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomha\\repos\\octagon_analysis\\trajectory_analysis\\trajectory_vectors.py:321: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cosine_similarity_this_wall = dot_product[wall_num]/(player_to_alcove_vector_norms[wall_num] * player_vector_norm)\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:47: RuntimeWarning: Mean of empty slice\n",
      "  return np.argmax(np.nanmean(cosine_similarity_trajectory, axis=1))\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:149: RuntimeWarning: Mean of empty slice\n",
      "  highest_alignment_val = np.max(np.nanmean(cosine_similarity_trajectory, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 retrievable choices for player_id 0\n",
      "81 first visible walls for player_id 0\n",
      "60 filtered trials for player_id 0\n",
      "41 high_low_trial_indices for player_id 0\n",
      "41 retrievable choices for player_id 0\n",
      "23 first visible walls for player_id 0\n",
      "23 filtered trials for player_id 0\n",
      "Trial list social length for experimentId 7 and playerId 1: 134\n",
      "109 high_low_trial_indices for player_id 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\tomha\\repos\\octagon_analysis\\trajectory_analysis\\trajectory_vectors.py:321: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  cosine_similarity_this_wall = dot_product[wall_num]/(player_to_alcove_vector_norms[wall_num] * player_vector_norm)\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:47: RuntimeWarning: Mean of empty slice\n",
      "  return np.argmax(np.nanmean(cosine_similarity_trajectory, axis=1))\n",
      "c:\\users\\tomha\\repos\\octagon_analysis\\analysis\\loser_inferred_choice.py:149: RuntimeWarning: Mean of empty slice\n",
      "  highest_alignment_val = np.max(np.nanmean(cosine_similarity_trajectory, axis=1))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 retrievable choices for player_id 1\n",
      "86 first visible walls for player_id 1\n",
      "81 filtered trials for player_id 1\n",
      "42 high_low_trial_indices for player_id 0\n",
      "42 retrievable choices for player_id 0\n",
      "28 first visible walls for player_id 0\n",
      "28 filtered trials for player_id 0\n"
     ]
    }
   ],
   "source": [
    "for experiment_id, players in analysis_results.items():\n",
    "    for player_id, data in players.items():\n",
    "        \n",
    "        # get the trial lists for this session and player\n",
    "        trial_list_social = trial_lists_social[experiment_id]\n",
    "        trial_list_solo = trial_lists_combined_solo[experiment_id*2 + player_id] # check this fits the above\n",
    "\n",
    "        # filter the trial list for regressor valid trials\n",
    "        print(f\"Trial list social length for experimentId {experiment_id} and playerId {player_id}: {len(trial_list_social)}\")\n",
    "        trial_list_social = [trial_list_social[i] for i in filter_valid_trial_indices(trial_list_social, player_id)]\n",
    "        trial_list_solo = [trial_list_solo[i] for i in filter_valid_trial_indices(trial_list_solo, player_id=0, solo=True)]\n",
    "        \n",
    "        # regressors social\n",
    "        player_data = analysis_results[experiment_id][player_id]['social']\n",
    "        distances = extract_distances_to_walls(trial_list_social, player_id)\n",
    "        player_data['regressors']['wall_sep'] = extract_wall_sep(trial_list_social)\n",
    "        player_data['regressors']['first_seen'] = extract_first_wall_seen(trial_list_social, player_id)\n",
    "        player_data['regressors']['d2h'] = distances[:,0]\n",
    "        player_data['regressors']['d2l'] = distances[:,1]\n",
    "        player_data['regressors']['opponent_visible'] = extract_opponent_visibility_slice_onset(trial_list_social, player_id)\n",
    "\n",
    "        # dependent variable social\n",
    "        player_data['dependent']['outcome'] = extract_trial_outcome(trial_list_social, player_id)\n",
    "\n",
    "        # regressors solo\n",
    "        player_data = analysis_results[experiment_id][player_id]['solo']\n",
    "        distances = extract_distances_to_walls(trial_list_solo, player_id=0)\n",
    "        player_data['regressors']['wall_sep'] = extract_wall_sep(trial_list_solo)\n",
    "        player_data['regressors']['first_seen'] = extract_first_wall_seen(trial_list_solo, player_id=0)\n",
    "        player_data['regressors']['d2h'] = distances[:,0]\n",
    "        player_data['regressors']['d2l'] = distances[:,1]\n",
    "\n",
    "        # dependent variable social\n",
    "        player_data['dependent']['outcome'] = extract_trial_outcome(trial_list_solo, player_id)\n",
    "\n",
    "        # regressors solo\n",
    "        player_data = analysis_results[experiment_id][player_id]['solo']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d8fe2a",
   "metadata": {},
   "source": [
    "#### Populate a dataframe, with a row for each trial, and fields for regressors (only including trials with fully-populated regressors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "08434f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_df_social = pd.DataFrame()\n",
    "\n",
    "for session_id, players in analysis_results.items():\n",
    "    for player_id in players:\n",
    "        \n",
    "        # take each filtered_regressor array and fill the relevant df field for this player\n",
    "        player_data = analysis_results[session_id][player_id]['social']['regressors']\n",
    "        outcome = analysis_results[session_id][player_id]['social']['dependent']['outcome']\n",
    "        df_player = pd.DataFrame(\n",
    "                    {\n",
    "                        \"SessionID\" : session_id,\n",
    "                        \"PlayerID\" : player_id,\n",
    "                        \"GlmPlayerID\" : session_id*2 + player_id,\n",
    "                        \"ChooseHigh\" : outcome,\n",
    "                        \"WallSep\" : player_data['wall_sep'],\n",
    "                        \"FirstSeenWall\" : player_data['first_seen'],\n",
    "                        \"D2H\" : player_data['d2h'],\n",
    "                        \"D2L\" : player_data['d2l'],\n",
    "                        \"OpponentVisible\" : player_data['opponent_visible']\n",
    "                    }\n",
    "        )\n",
    "\n",
    "\n",
    "        # append this smaller dataframe to the the full dataframe\n",
    "        glm_df_social = pd.concat([glm_df_social, df_player], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4587511",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_df_solo = pd.DataFrame()\n",
    "\n",
    "for session_id, players in analysis_results.items():\n",
    "    for player_id in players:\n",
    "        \n",
    "        # take each filtered_regressor array and fill the relevant df field for this player\n",
    "        player_data = analysis_results[session_id][player_id]['solo']['regressors']\n",
    "        outcome = analysis_results[session_id][player_id]['solo']['dependent']['outcome']\n",
    "        df_player = pd.DataFrame(\n",
    "                    {\n",
    "                        \"SessionID\" : session_id,\n",
    "                        \"PlayerID\" : player_id,\n",
    "                        \"GlmPlayerID\" : session_id,\n",
    "                        \"ChooseHigh\" : outcome,\n",
    "                        \"WallSep\" : player_data['wall_sep'],\n",
    "                        \"FirstSeenWall\" : player_data['first_seen'],\n",
    "                        \"D2H\" : player_data['d2h'],\n",
    "                        \"D2L\" : player_data['d2l']\n",
    "                    }\n",
    "        )\n",
    "\n",
    "        # append this smaller dataframe to the the full dataframe\n",
    "        glm_df_solo = pd.concat([glm_df_solo, df_player], ignore_index=True)\n",
    "\n",
    "\n",
    "glm_df_solo[\"FirstSeenWall\"] = glm_df_solo[\"FirstSeenWall\"].astype(\"category\")\n",
    "glm_df_solo[\"WallSep\"] = glm_df_solo[\"WallSep\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018b83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_df_solo[(glm_df_solo['SessionID'] == 2) & (glm_df_solo['PlayerID'] == 0)].iloc[-20:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1fa7c35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.0\n",
       "1       1.0\n",
       "2       1.0\n",
       "3       1.0\n",
       "4       2.0\n",
       "       ... \n",
       "2466    1.0\n",
       "2467    1.0\n",
       "2468    1.0\n",
       "2469    2.0\n",
       "2470    1.0\n",
       "Name: ChooseHigh, Length: 2471, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_df['ChooseHigh']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecf4ac5",
   "metadata": {},
   "source": [
    "### Build the GLM in statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "adff06a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9fbf9aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             ChooseHigh   No. Observations:                 2471\n",
      "Model:                            GLM   Df Residuals:                     2467\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                   -inf\n",
      "Date:                Mon, 10 Feb 2025   Deviance:                   1.2997e+05\n",
      "Time:                        15:10:07   Pearson chi2:                 7.55e+18\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):                nan\n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept             4.591e+15   3.51e+06   1.31e+09      0.000    4.59e+15    4.59e+15\n",
      "FirstSeenWall[T.2.0] -3.853e+15    2.7e+06  -1.43e+09      0.000   -3.85e+15   -3.85e+15\n",
      "WallSep              -3.256e+12   1.07e+06  -3.05e+06      0.000   -3.26e+12   -3.26e+12\n",
      "PlayerWin             3.253e+15   2.73e+06   1.19e+09      0.000    3.25e+15    3.25e+15\n",
      "========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Tom\\miniconda3\\envs\\octagon_analysis\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: invalid value encountered in log\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "d:\\Users\\Tom\\miniconda3\\envs\\octagon_analysis\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1057: RuntimeWarning: invalid value encountered in log\n",
      "  n * np.log(1 - mu + 1e-20)) * var_weights\n"
     ]
    }
   ],
   "source": [
    "# # Convert categorical predictors into factors\n",
    "glm_df[\"Separation\"] = glm_df[\"WallSep\"].astype(\"category\")\n",
    "glm_df[\"Outcome\"] = glm_df[\"PlayerWin\"].astype(\"category\")\n",
    "glm_df[\"FirstSeenWall\"] = glm_df[\"FirstSeenWall\"].astype(\"category\")\n",
    "\n",
    "# Fit a logistic regression (GLM with binomial link)\n",
    "glm_model = smf.glm(\n",
    "    formula=\"ChooseHigh ~ WallSep + PlayerWin + FirstSeenWall\",\n",
    "    data=glm_df,\n",
    "    family=sm.families.Binomial()\n",
    ").fit()\n",
    "\n",
    "# Display the results\n",
    "print(glm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c001a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "smf.mixedlm(\"Outcome ~ X1 + X2\", data, groups=data[\"PlayerID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ca99f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "glmm_model = smf.mixedlm(\n",
    "\n",
    "    formula = \"ChooseHigh ~ WallSep + PlayerWin + FirstSeenWall\",\n",
    "    data = glm_df,\n",
    "    groups = glm_df['GlmPlayerID'],\n",
    "    family = sm.families.Binomial()\n",
    ").fit()\n",
    "\n",
    "print(glmm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc72ab8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from pymer4.models import Lmer\n",
    "\n",
    "model_formula = 'ChooseHigh ~ D2L + D2H + FirstSeenWall + WallSep + (1|GlmPlayerID)'\n",
    "\n",
    "model = Lmer(model_formula, data=glm_df_solo, family='binomial')\n",
    "results=model.fit()\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octagon_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
