{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7165c571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[1] \"R version 4.1.3 (2022-03-10)\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "# os.environ['R_HOME']= r'C:\\Users\\tomha\\miniconda3\\envs\\octagon_analysis\\lib\\R'\n",
    "os.environ['R_HOME']= r'D:\\Users\\Tom\\miniconda3\\envs\\octagon_analysis\\lib\\R'\n",
    "# os.environ['R_HOME']= '/home/tom/miniconda3/envs/octagon_analysis/lib/R'\n",
    "\n",
    "import rpy2\n",
    "\n",
    "import rpy2.robjects as robjects\n",
    "print(robjects.r('R.version.string'))\n",
    "\n",
    "import parse_data.prepare_data as prepare_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# import globals\n",
    "import data_strings\n",
    "import data_extraction.get_indices as get_indices\n",
    "import analysis.wall_visibility_and_choice as wall_visibility_and_choice\n",
    "from trajectory_analysis import trajectory_vectors\n",
    "from plotting import plot_octagon\n",
    "import parse_data.identify_filepaths as identify_filepaths \n",
    "from data_extraction.trial_list_filters import filter_trials_other_visible\n",
    "from analysis import opponent_visibility\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import time\n",
    "from pymer4.models import Lmer\n",
    "import populate_dataframes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb7e93d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 20\n",
    "split_dataframes = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71cf003",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "08a034bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "analysis_dir = os.path.join('..', 'data')\n",
    "analysis_file = 'analysis_results_2levelsforFirstSeenWall.pkl'\n",
    "filename = os.path.join(analysis_dir, analysis_file)\n",
    "# load the analysis results\n",
    "with open(filename, 'rb') as f:\n",
    "    analysis_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5eda65",
   "metadata": {},
   "source": [
    "### populate dataframes for glm input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8913bcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate dataframes for solo, solosocial, and social analysis_type\n",
    "glm_df_solo = populate_dataframes.populate_dataframe(analysis_results, analysis_type='solo')\n",
    "glm_df_solosocial = populate_dataframes.populate_dataframe(analysis_results, analysis_type='solosocial')\n",
    "glm_df_social = populate_dataframes.populate_dataframe(analysis_results, analysis_type='social')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be390a9d",
   "metadata": {},
   "source": [
    "### create reference to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ed566cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'glm_df_solo': glm_df_solo,\n",
    "    'glm_df_solosocial': glm_df_solosocial,\n",
    "    'glm_df_social': glm_df_social\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a02e26",
   "metadata": {},
   "source": [
    "### shuffle the dataframes for k-fold index selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41d72dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_dataframes = os.path.join('..', 'data', 'shuffled_dataframes.pkl')\n",
    "\n",
    "if split_dataframes:\n",
    "    \n",
    "    # shuffle each dataframe\n",
    "    for name, df in dataframes.items():\n",
    "        dataframes[name] = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # pickle save shuffled dataframes to sandbox > data, as one dictionary\n",
    "    with open(shuffled_dataframes, 'wb') as f:\n",
    "        pickle.dump(dataframes, f)\n",
    "\n",
    "else:\n",
    "    # load the shuffled dataframes\n",
    "    with open(shuffled_dataframes, 'rb') as f:\n",
    "        shuffled_dataframes = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1122a240",
   "metadata": {},
   "source": [
    "### Split each dataframe into folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b531ca51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Tom\\miniconda3\\envs\\octagon_analysis\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# split each dataframe into k equal parts\n",
    "split_dataframes = {name: np.array_split(df, k) for name, df in dataframes.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18da8cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1939740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lmer_models(dataframes, split_dataframes, model_formula):\n",
    "    \"\"\"\n",
    "    For each dataframe type, hold out one fold of the split dataframe, \n",
    "    and fit a Lmer binomial model on the remaining folds.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframes: dict, original dataframes\n",
    "    - split_dataframes: dict, split dataframes into folds\n",
    "    - model_formula: str, formula for the Lmer model\n",
    "\n",
    "    Returns:\n",
    "    - models_dict: dict, models for each dataframe type\n",
    "    \"\"\"\n",
    "    models_dict = {}\n",
    "\n",
    "    for df_name, folds in split_dataframes.items():\n",
    "        models = []\n",
    "        print(f\"Fitting models for {df_name}...\")\n",
    "        for i in range(len(folds)):\n",
    "            # Combine all folds except the i-th fold\n",
    "            train_data = pd.concat(folds[:i] + folds[i+1:], ignore_index=True)\n",
    "            \n",
    "            # Fit the Lmer model\n",
    "            model = Lmer(model_formula, data=train_data, family='binomial')\n",
    "            model.fit()\n",
    "            models.append(model)\n",
    "        \n",
    "        models_dict[df_name] = models\n",
    "    \n",
    "    return models_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee3414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import redirect_stdout\n",
    "\n",
    "def fit_models(analysis_type, split_dataframes_dict, model_formula, k):\n",
    "    \n",
    "    # get the dataframe for the analysis type\n",
    "    dataframe_name = f'glm_df_{analysis_type}'\n",
    "    split_dataframes = split_dataframes_dict[dataframe_name]\n",
    "\n",
    "    models = []\n",
    "    max_count = k\n",
    "    f = IntProgress(min=0, max=max_count, description='Fitting models')\n",
    "    display(f)\n",
    "\n",
    "    # Suppress the output of the models fitting process\n",
    "    with open(os.devnull, 'w') as fnull:\n",
    "        with redirect_stdout(fnull):\n",
    "            for i, df in enumerate(split_dataframes):\n",
    "                model = Lmer(model_formula, data=df, family='binomial')\n",
    "                model.fit()\n",
    "                models.append(model)\n",
    "                print(f\"Model {i} fit with {len(df)} rows\")\n",
    "                f.value += 1\n",
    "\n",
    "\n",
    "    \n",
    "    return models\n",
    "\n",
    "\n",
    "def calculate_predictions(models, original_df_size, dfs_with_removed_row_sampled, random_indices):\n",
    "    \n",
    "    predictions = np.full(len(dfs_with_removed_row_sampled), np.nan)\n",
    "    predictions_maintained_index = np.full(original_df_size, np.nan)\n",
    "    for i, model in enumerate(models):\n",
    "        # get the row that was removed for this model\n",
    "        removed_row = dfs_with_removed_row_sampled[i]\n",
    "        \n",
    "        # get the prediction for this row\n",
    "        prediction = model.predict(removed_row, skip_data_checks=True, verify_predictions=False)\n",
    "        \n",
    "        # assign the prediction to the correct index in the predictions array\n",
    "        predictions_maintained_index[random_indices[i]] = prediction[0]\n",
    "\n",
    "        # also assign the prediction to the next index of a new array\n",
    "        predictions[i] = prediction[0]\n",
    "\n",
    "    return predictions, predictions_maintained_index\n",
    "\n",
    "def calculate_likelihoods(df, predictions_maintained_index, random_indices):\n",
    "    \n",
    "    # calculate the metric for each prediction\n",
    "    likelihoods = np.full(len(random_indices), np.nan)\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        predicted_output = predictions_maintained_index[idx]\n",
    "        true_output = df.iloc[idx]['ChooseHigh']\n",
    "        likelihood = predicted_output**true_output * (1 - predicted_output)**(1 - true_output)\n",
    "        likelihoods[i] = likelihood\n",
    "\n",
    "    return likelihoods\n",
    "\n",
    "def calculate_nll(likelihoods):\n",
    "    # #### sum the logs of the likelihoods, and take the negative\n",
    "    summed_log_likelihoods = np.sum(np.log(likelihoods)) \n",
    "    nll = -summed_log_likelihoods\n",
    "\n",
    "    return nll\n",
    "\n",
    "def save_cross_validation_results(name, model_formula, df, random_indices, predictions, nll):\n",
    "    ''' Save the cross-validation results to a file. '''\n",
    "    \n",
    "    cross_validation_results = {\n",
    "        \"name\": name,\n",
    "        \"model_formula\": model_formula,\n",
    "        \"dataframe\": df,\n",
    "        \"random_indices\" : random_indices,\n",
    "        # \"models\" : models,\n",
    "        \"predictions\" : predictions,\n",
    "        \"nll\" : nll\n",
    "    }\n",
    "\n",
    "   # Save the cross-validation results to a file\n",
    "    dir = os.path.join('..', 'data')\n",
    "    filename = f'CV_results_{name}.pickle'\n",
    "    filepath = os.path.join(dir, filename)\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(cross_validation_results, f)\n",
    "\n",
    "    print(\"CV data saved to: \", filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf06e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octagon_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
