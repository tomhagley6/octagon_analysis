{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4992911-7b02-448c-8ee5-c89c228ad2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import parse_data.prepare_data as prepare_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import globals\n",
    "import data_strings\n",
    "import data_extraction.get_indices as get_indices\n",
    "import analysis.wall_visibility_and_choice as wall_visibility_and_choice\n",
    "from trajectory_analysis import trajectory_vectors\n",
    "from plotting import plot_octagon\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a24b223",
   "metadata": {},
   "source": [
    "### Create a dataframe to feed into a GLM using Choice, Outcome, Wall Separation, and PlayerID to predict P(Choose High)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "011c819a-ab6d-4c42-8ab8-c35d0824fbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = data_strings.DATA_FOLDER\n",
    "json_filenames_all_social = data_strings.JSON_FILENAMES_SOCIAL\n",
    "json_filenames_all_solo = data_strings.JSON_FILENAMES_SOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c07cb011",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_filenames = json_filenames_all_social[:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "167898aa-3073-479e-8eef-6c579c67c7f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\240913_1\\2024-09-13_11-31-00_YW13_JL13_Social.json\n",
      "Data is from period before 2024-09-13 00:00:00\n",
      "Running dataframe through playerinfo_playerposition_conversion.\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\240927_1\\2024-09-27_14-25-20_SH27_EN27_Social.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\241017_1\\2024-10-17_14-28-40_SP17_AW17_Social.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\241017_2\\2024-10-17_16-41-38_ZH17_EM17_Social.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\241112_1\\2024-11-12_13-31-14_KA12_WM12_Social.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\241112_2\\2024-11-12_15-23-24_FA12_SS12_Social.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\241113_1\\2024-11-13_14-18-54_NK13_RD13_Social.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n",
      "filepath: C:\\Users\\tomha\\OneDrive\\PhD\\SWC\\data\\241113_2\\2024-11-13_15-28-07_YL13_HK13_Social.json\n",
      "Loading complete.\n",
      "Preprocessing complete.\n"
     ]
    }
   ],
   "source": [
    "df, trial_lists = prepare_data.prepare_data(data_folder, json_filenames, combine=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46092b8",
   "metadata": {},
   "source": [
    "### Regressor value extraction functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78024b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_wall_sep(trial_list):\n",
    "    \n",
    "    wall_sep = np.full(len(trial_list), np.nan)\n",
    "    for i, trial in enumerate(trial_list):\n",
    "        wall_sep_this_trial = get_indices.get_wall_difference(trial=trial)\n",
    "        wall_sep[i] = wall_sep_this_trial\n",
    "\n",
    "    return wall_sep\n",
    "\n",
    "def extract_first_wall_seen(trial_list, player_id):\n",
    "        \n",
    "    high_wall_first_visible_session = wall_visibility_and_choice.get_given_wall_first_visible_session(trial_list,\n",
    "                                                                                                        player_id,\n",
    "                                                                                                        wall_index=0,\n",
    "                                                                                                        current_fov=110)\n",
    "\n",
    "    low_wall_first_visible_session = wall_visibility_and_choice.get_given_wall_first_visible_session(trial_list,\n",
    "                                                                                                        player_id, \n",
    "                                                                                                        wall_index=1,\n",
    "                                                                                                        current_fov=110)\n",
    "    low_wall_first_visible_session = low_wall_first_visible_session*2\n",
    "    \n",
    "    first_visible_session = high_wall_first_visible_session + low_wall_first_visible_session\n",
    "\n",
    "    return first_visible_session\n",
    "\n",
    "\n",
    "def extract_player_choice(trial_list, player_id, inferred_choice):\n",
    "    \n",
    "    # array of wall numbers where player won, np.nan where player did not\n",
    "    player_choice = wall_visibility_and_choice.get_player_wall_choice(trial_list, player_id,\n",
    "                                                                        inferred_choice=inferred_choice, debug=False)\n",
    "\n",
    "    # 2 where player chose High, 0 where player chose Low, np.nan where player lost\n",
    "    high_wall_chosen_session = get_indices.was_given_wall_chosen(trial_list, player_choice,\n",
    "                                                                    given_wall_index=0)\n",
    "    high_wall_chosen_session = high_wall_chosen_session*2\n",
    "\n",
    "    # 1 where player chose Low, 0 where player chose High, np.nan where player lost\n",
    "    low_wall_chosen_session  = get_indices.was_given_wall_chosen(trial_list, player_choice,\n",
    "                                                                    given_wall_index=1)\n",
    "\n",
    "    # 1 or 2 where player chose Low or High respectively, np.nan where player lost\n",
    "    chosen_wall_session = high_wall_chosen_session + low_wall_chosen_session\n",
    "\n",
    "    return chosen_wall_session\n",
    "\n",
    "\n",
    "def extract_trial_outcome(trial_list, player_id):\n",
    "    \n",
    "    trigger_activators = get_indices.get_trigger_activators(trial_list)\n",
    "    this_player_won = (trigger_activators-1)*-1 if player_id == 0 else trigger_activators\n",
    "\n",
    "    return this_player_won"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65114032",
   "metadata": {},
   "source": [
    "### Extract 1D arrays for each player for the regressor values (Sandbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab068cf",
   "metadata": {},
   "source": [
    "#### Wall Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39d312f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_list = trial_lists[6]\n",
    "\n",
    "wall_sep = np.full(len(trial_list), np.nan)\n",
    "for i, trial in enumerate(trial_list):\n",
    "    wall_sep_this_trial = get_indices.get_wall_difference(trial=trial)\n",
    "    wall_sep[i] = wall_sep_this_trial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea032ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3157894736842105"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(wall_sep == 4)/np.count_nonzero(wall_sep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad36678b",
   "metadata": {},
   "source": [
    "#### First Seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad9e6ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "player_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f750de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "high_wall_first_visible_session = wall_visibility_and_choice.get_given_wall_first_visible_session(trial_list,\n",
    "                                                                                                    player_id,\n",
    "                                                                                                    wall_index=0,\n",
    "                                                                                                    current_fov=110)\n",
    "\n",
    "low_wall_first_visible_session = wall_visibility_and_choice.get_given_wall_first_visible_session(trial_list,\n",
    "                                                                                                     player_id, \n",
    "                                                                                                     wall_index=1,\n",
    "                                                                                                     current_fov=110)\n",
    "low_wall_first_visible_session = low_wall_first_visible_session*2\n",
    "\n",
    "\n",
    "\n",
    "first_visible_session = high_wall_first_visible_session + low_wall_first_visible_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0a8e860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 1., 2., 0., 0., 2., 1., 1., 1., 2., 2., 1., 1., 2., 2., 2.,\n",
       "       2., 2., 1., 1., 0., 0., 2., 2., 0., 2., 2., 1., 2., 2., 2., 2., 2.,\n",
       "       2., 2., 0., 1., 1., 2., 2., 0., 2., 1., 0., 0., 2., 2., 1., 0., 2.,\n",
       "       2., 0., 2., 0., 0., 1., 1., 1., 1., 2., 2., 2., 2., 1., 2., 2., 2.,\n",
       "       2., 1., 1., 1., 1., 1., 2., 2., 2., 1., 2., 2., 0., 2., 1., 1., 2.,\n",
       "       2., 2., 2., 1., 1., 0., 2., 2., 2., 1., 1., 2., 1., 1., 0., 2., 1.,\n",
       "       1., 2., 1., 2., 2., 2., 2., 1., 1., 2., 1., 0.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_visible_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf06370",
   "metadata": {},
   "source": [
    "#### Distance to High, Low\n",
    "(Check code validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67242f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get octagon alcove coordinates\n",
    "alcove_coordinates = plot_octagon.return_alcove_centre_points()\n",
    "\n",
    "start_positions = np.full((len(trial_list), 2), np.nan)\n",
    "session_walls = np.full((len(trial_list), 2), np.nan)\n",
    "distances = np.full((len(trial_list), 2), np.nan)\n",
    "\n",
    "# get distances for each trial in the session\n",
    "for i, trial in enumerate(trial_list):\n",
    "    # get WALL_1 and WALL_2 for each trial in the session\n",
    "    trial_walls = get_indices.get_walls(trial)\n",
    "    high_wall_idx = trial_walls[0] - 1\n",
    "    low_wall_idx = trial_walls[1] - 1\n",
    "    trial_high_coordinates = alcove_coordinates[:,high_wall_idx]\n",
    "    trial_low_coordinates = alcove_coordinates[:, low_wall_idx]\n",
    "\n",
    "    # index trajectory at timepoint 0 to get starting position\n",
    "    trajectory = trajectory_vectors.extract_trial_player_trajectory(trial=trial, player_id=player_id)\n",
    "    trial_start_position = trajectory[:,0]\n",
    "\n",
    "    # find distance between start position and WALL_1/WALL_2\n",
    "    d2h = np.linalg.norm(trial_high_coordinates - trial_start_position) # WALL_1\n",
    "    d2l = np.linalg.norm(trial_low_coordinates - trial_start_position)\n",
    "\n",
    "    session_walls[i,:] = trial_walls \n",
    "    start_positions[i,:] = trial_start_position\n",
    "    distances[i,:] = np.hstack((d2h, d2l))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029bb240",
   "metadata": {},
   "source": [
    "### Filter trials to only include those with full information for the GLM \n",
    "- Remove trials without recorded choice (np.nan in choice array) (whether I'm using inferred-choice or not)\n",
    "- Remove trials without a first visible wall (np.nan in first seen array)\n",
    "- Filter HighLow trials initially\n",
    "\n",
    "The best way to do the above may be to keep an array of 'original indices', filter this array in the same way as I do my normal trial list filtering, and then I have an indices array with preserved numbering that I can use to index valid trials to add to my dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c09c4dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify indices of trial list with HighLow trials\n",
    "high_low_trial_indices = get_indices.get_trials_trialtype(trial_list, trial_type=globals.HIGH_LOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8438e5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply masks for one visible wall, and a retrievable choice, to the set of HighLow trials\n",
    "retrievable_choice_mask = ~np.isnan(chosen_wall_session_wins_and_losses[high_low_trial_indices])\n",
    "one_wall_first_visible_mask = first_visible_session[high_low_trial_indices] > 0\n",
    "\n",
    "# combine masks into one \n",
    "final_mask = retrievable_choice_mask & one_wall_first_visible_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b82f3c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_indices = high_low_trial_indices[final_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4af44dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  12,  15,  17,  18,\n",
       "        20,  21,  22,  24,  26,  31,  32,  33,  36,  37,  38,  39,  41,\n",
       "        43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  56,  57,\n",
       "        61,  64,  71,  72,  73,  77,  78,  82,  83,  85,  89,  90,  92,\n",
       "        93,  95,  97,  98, 100, 101, 102, 103, 104, 105, 106, 109, 110,\n",
       "       111, 113, 114, 121, 122, 123, 125, 131, 132, 134])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53652f8c",
   "metadata": {},
   "source": [
    "#### Filtering function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "211a5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_valid_trial_indices(trial_list, first_visible_session, chosen_wall_session):\n",
    "\n",
    "    # identify indices of trial list with HighLow trials\n",
    "    high_low_trial_indices = get_indices.get_trials_trialtype(trial_list, trial_type=globals.HIGH_LOW)\n",
    "\n",
    "    # apply masks for one visible wall, and a retrievable choice, to the set of HighLow trials\n",
    "    retrievable_choice_mask = ~np.isnan(chosen_wall_session[high_low_trial_indices])\n",
    "    one_wall_first_visible_mask = first_visible_session[high_low_trial_indices] > 0\n",
    "\n",
    "    # combine masks into one \n",
    "    final_mask = retrievable_choice_mask & one_wall_first_visible_mask\n",
    "\n",
    "    filtered_indices = np.array(high_low_trial_indices)[final_mask]\n",
    "\n",
    "    return filtered_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d1d09b",
   "metadata": {},
   "source": [
    "### Create a dictionary to hold, for each session and player, regressor values for the session, only including trials with fully-populated regessors\n",
    "- Fields for each of the regressors applied to all trials\n",
    "- Fields for each of the regressors with only valid trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f1d70320",
   "metadata": {},
   "outputs": [],
   "source": [
    "solo = False\n",
    "player_ids = [0] if solo else [0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "725c0ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_results = {\n",
    "    session_id: {\n",
    "        player_id: {\n",
    "\n",
    "            # unfiltered regressors\n",
    "            'regressors': {\n",
    "                'wall_sep': None,\n",
    "                'first_seen': None,\n",
    "                'choice': None,\n",
    "                'outcome': None\n",
    "            },\n",
    "\n",
    "            # regressors filtered for trials fully-populated regressor values\n",
    "            'regressors_filtered': {\n",
    "                'wall_sep': None,\n",
    "                'first_seen': None,\n",
    "                'choice': None,\n",
    "                'outcome': None\n",
    "            }\n",
    "        }\n",
    "        for player_id in player_ids\n",
    "    }\n",
    "    for session_id in np.arange(len(trial_lists))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a932ecf8",
   "metadata": {},
   "source": [
    "### Populate the dictionary with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d364c67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_choice = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "56952ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(analysis_results[14][1]['regressors_filtered']['outcome'] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "651901d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1., -0., -0.,  1.,  1.,  1.,  1.,  1.,  1., -0.,  1.,  1., -0.,\n",
       "       -0.,  1.,  1., -0., -0.,  1., -0.,  1.,  1., -0.,  1.,  1., -0.,\n",
       "       -0., -0., -0.,  1.,  1., -0.,  1., -0.,  1.,  1.,  1., -0., -0.,\n",
       "       -0., -0., -0.,  1., -0.,  1.,  1., -0.,  1., -0., -0.,  1., -0.,\n",
       "       -0., -0., -0.,  1.,  1.,  1., -0., -0., -0.,  1.,  1., -0.,  1.,\n",
       "        1., -0., -0.,  1., -0.])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_results[14][0]['regressors_filtered']['outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c173632",
   "metadata": {},
   "outputs": [],
   "source": [
    "for session_id, players in analysis_results.items():\n",
    "    for player_id, data in players.items():\n",
    "        \n",
    "        # get the trial list for this session\n",
    "        trial_list = trial_lists[session_id]\n",
    "        \n",
    "        # get regressors for all trials in session\n",
    "        player_data = analysis_results[session_id][player_id]['regressors']\n",
    "        player_data['wall_sep'] = extract_wall_sep(trial_list)\n",
    "        player_data['first_seen'] = extract_first_wall_seen(trial_list, player_id)\n",
    "        player_data['choice'] = extract_player_choice(trial_list, player_id, inferred_choice)\n",
    "        player_data['outcome'] = extract_trial_outcome(trial_list, player_id)\n",
    "\n",
    "        # filtered the trials to only include those with fully-populated regressors, and store for only these indices\n",
    "        filtered_indices = filter_valid_trial_indices(trial_list, player_data['first_seen'], player_data['choice'])\n",
    "\n",
    "        # account for filtering removing all trials from a player\n",
    "        if filtered_indices.size > 0:\n",
    "            player_data_valid_trials = analysis_results[session_id][player_id]['regressors_filtered']\n",
    "            player_data_valid_trials['wall_sep'] = player_data['wall_sep'][filtered_indices]\n",
    "            player_data_valid_trials['first_seen'] = player_data['first_seen'][filtered_indices]\n",
    "            player_data_valid_trials['choice'] = player_data['choice'][filtered_indices]\n",
    "            player_data_valid_trials['outcome'] = player_data['outcome'][filtered_indices]\n",
    "        else:\n",
    "            player_data_valid_trials['wall_sep'] = np.array([])\n",
    "            player_data_valid_trials['first_seen'] = np.array([])\n",
    "            player_data_valid_trials['choice'] = np.array([])\n",
    "            player_data_valid_trials['outcome'] = np.array([])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d8fe2a",
   "metadata": {},
   "source": [
    "#### Populate a dataframe, with a row for each trial, and fields for regressors (only including trials with fully-populated regressors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "08434f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_df = pd.DataFrame()\n",
    "\n",
    "for session_id, players in analysis_results.items():\n",
    "    for player_id in players:\n",
    "        \n",
    "        # take each filtered_regressor array and fill the relevant df field for this player\n",
    "        player_data = analysis_results[session_id][player_id]['regressors_filtered']\n",
    "        df_player = pd.DataFrame(\n",
    "                    {\n",
    "                        \"SessionID\" : session_id,\n",
    "                        \"PlayerID\" : player_id,\n",
    "                        \"GlmPlayerID\" : session_id*2 + player_id,\n",
    "                        \"WallSep\" : player_data['wall_sep'],\n",
    "                        \"FirstSeenWall\" : player_data['first_seen'],\n",
    "                        \"ChooseHigh\" : player_data['choice'],\n",
    "                        \"PlayerWin\" : player_data['outcome']\n",
    "                    }\n",
    "        )\n",
    "\n",
    "\n",
    "        # append this smaller dataframe to the the full dataframe\n",
    "        glm_df = pd.concat([glm_df, df_player], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "018b83d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SessionID</th>\n",
       "      <th>PlayerID</th>\n",
       "      <th>GlmPlayerID</th>\n",
       "      <th>WallSep</th>\n",
       "      <th>FirstSeenWall</th>\n",
       "      <th>ChooseHigh</th>\n",
       "      <th>PlayerWin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1924</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1927</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1928</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1929</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1930</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1933</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SessionID  PlayerID  GlmPlayerID  WallSep  FirstSeenWall  ChooseHigh  PlayerWin\n",
       "1924         14         1           29      1.0            2.0         1.0        1.0\n",
       "1925         14         1           29      2.0            2.0         1.0        1.0\n",
       "1926         14         1           29      1.0            2.0         2.0        1.0\n",
       "1927         14         1           29      4.0            1.0         0.0        0.0\n",
       "1928         14         1           29      2.0            1.0         2.0        0.0\n",
       "1929         14         1           29      1.0            2.0         2.0        0.0\n",
       "1930         14         1           29      2.0            1.0         2.0        1.0\n",
       "1931         14         1           29      1.0            1.0         2.0        1.0\n",
       "1932         14         1           29      2.0            2.0         1.0        1.0\n",
       "1933         14         1           29      1.0            2.0         1.0        1.0"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_df[(glm_df['SessionID'] == 14) & (glm_df['PlayerID'] == 1)].iloc[-20:-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1fa7c35e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.0\n",
       "1       1.0\n",
       "2       1.0\n",
       "3       1.0\n",
       "4       2.0\n",
       "       ... \n",
       "2466    1.0\n",
       "2467    1.0\n",
       "2468    1.0\n",
       "2469    2.0\n",
       "2470    1.0\n",
       "Name: ChooseHigh, Length: 2471, dtype: float64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glm_df['ChooseHigh']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecf4ac5",
   "metadata": {},
   "source": [
    "### Build the GLM in statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "adff06a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9fbf9aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:             ChooseHigh   No. Observations:                 2471\n",
      "Model:                            GLM   Df Residuals:                     2467\n",
      "Model Family:                Binomial   Df Model:                            3\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                   -inf\n",
      "Date:                Mon, 10 Feb 2025   Deviance:                   1.2997e+05\n",
      "Time:                        15:10:07   Pearson chi2:                 7.55e+18\n",
      "No. Iterations:                     4   Pseudo R-squ. (CS):                nan\n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "Intercept             4.591e+15   3.51e+06   1.31e+09      0.000    4.59e+15    4.59e+15\n",
      "FirstSeenWall[T.2.0] -3.853e+15    2.7e+06  -1.43e+09      0.000   -3.85e+15   -3.85e+15\n",
      "WallSep              -3.256e+12   1.07e+06  -3.05e+06      0.000   -3.26e+12   -3.26e+12\n",
      "PlayerWin             3.253e+15   2.73e+06   1.19e+09      0.000    3.25e+15    3.25e+15\n",
      "========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\Tom\\miniconda3\\envs\\octagon_analysis\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1056: RuntimeWarning: invalid value encountered in log\n",
      "  special.gammaln(n - y + 1) + y * np.log(mu / (1 - mu + 1e-20)) +\n",
      "d:\\Users\\Tom\\miniconda3\\envs\\octagon_analysis\\Lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1057: RuntimeWarning: invalid value encountered in log\n",
      "  n * np.log(1 - mu + 1e-20)) * var_weights\n"
     ]
    }
   ],
   "source": [
    "# # Convert categorical predictors into factors\n",
    "glm_df[\"Separation\"] = glm_df[\"WallSep\"].astype(\"category\")\n",
    "glm_df[\"Outcome\"] = glm_df[\"PlayerWin\"].astype(\"category\")\n",
    "glm_df[\"FirstSeenWall\"] = glm_df[\"FirstSeenWall\"].astype(\"category\")\n",
    "\n",
    "# Fit a logistic regression (GLM with binomial link)\n",
    "glm_model = smf.glm(\n",
    "    formula=\"ChooseHigh ~ WallSep + PlayerWin + FirstSeenWall\",\n",
    "    data=glm_df,\n",
    "    family=sm.families.Binomial()\n",
    ").fit()\n",
    "\n",
    "# Display the results\n",
    "print(glm_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c001a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "smf.mixedlm(\"Outcome ~ X1 + X2\", data, groups=data[\"PlayerID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "38ca99f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "argument family not permitted for MixedLM initialization",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[154], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m glmm_model \u001b[38;5;241m=\u001b[39m \u001b[43msmf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmixedlm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mformula\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mChooseHigh ~ WallSep + PlayerWin + FirstSeenWall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mglm_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mglm_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGlmPlayerID\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfamilies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBinomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfit()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(glmm_model\u001b[38;5;241m.\u001b[39msummary())\n",
      "File \u001b[1;32md:\\Users\\Tom\\miniconda3\\envs\\octagon_analysis\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:1046\u001b[0m, in \u001b[0;36mMixedLM.from_formula\u001b[1;34m(cls, formula, data, re_formula, vc_formula, subset, use_sparse, missing, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1044\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexog_vc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m exog_vc\n\u001b[0;32m   1045\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroups\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m groups\n\u001b[1;32m-> 1046\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_formula\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformula\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;66;03m# expand re names to account for pairs of RE\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m (param_names,\n\u001b[0;32m   1050\u001b[0m  exog_re_names,\n\u001b[0;32m   1051\u001b[0m  exog_re_names_full) \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m_make_param_names(exog_re_names)\n",
      "File \u001b[1;32md:\\Users\\Tom\\miniconda3\\envs\\octagon_analysis\\Lib\\site-packages\\statsmodels\\base\\model.py:229\u001b[0m, in \u001b[0;36mModel.from_formula\u001b[1;34m(cls, formula, data, subset, drop_cols, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m         design_info \u001b[38;5;241m=\u001b[39m design_info\u001b[38;5;241m.\u001b[39msubset(cols)\n\u001b[0;32m    225\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing_idx\u001b[39m\u001b[38;5;124m'\u001b[39m: missing_idx,\n\u001b[0;32m    226\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmissing\u001b[39m\u001b[38;5;124m'\u001b[39m: missing,\n\u001b[0;32m    227\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mformula\u001b[39m\u001b[38;5;124m'\u001b[39m: formula,  \u001b[38;5;66;03m# attach formula for unpckling\u001b[39;00m\n\u001b[0;32m    228\u001b[0m                \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdesign_info\u001b[39m\u001b[38;5;124m'\u001b[39m: design_info})\n\u001b[1;32m--> 229\u001b[0m mod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m mod\u001b[38;5;241m.\u001b[39mformula \u001b[38;5;241m=\u001b[39m formula\n\u001b[0;32m    231\u001b[0m \u001b[38;5;66;03m# since we got a dataframe, attach the original\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\Tom\\miniconda3\\envs\\octagon_analysis\\Lib\\site-packages\\statsmodels\\regression\\mixed_linear_model.py:704\u001b[0m, in \u001b[0;36mMixedLM.__init__\u001b[1;34m(self, endog, exog, groups, exog_re, exog_vc, use_sqrt, missing, **kwargs)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _allowed_kwargs:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    705\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124margument \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m not permitted for MixedLM initialization\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m x)\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_sqrt \u001b[38;5;241m=\u001b[39m use_sqrt\n\u001b[0;32m    709\u001b[0m \u001b[38;5;66;03m# Some defaults\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: argument family not permitted for MixedLM initialization"
     ]
    }
   ],
   "source": [
    "glmm_model = smf.mixedlm(\n",
    "\n",
    "    formula = \"ChooseHigh ~ WallSep + PlayerWin + FirstSeenWall\",\n",
    "    data = glm_df,\n",
    "    groups = glm_df['GlmPlayerID'],\n",
    "    family = sm.families.Binomial()\n",
    ").fit()\n",
    "\n",
    "print(glmm_model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "octagon_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
